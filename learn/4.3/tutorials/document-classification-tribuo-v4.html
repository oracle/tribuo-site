---
title: "Document Classification"
og-title: "Document Classification Tutorial"
learn_nav: true
parent: Tutorials
nav_order: 311
is_notebook: true
notebook_url: https://github.com/oracle/tribuo/blob/main/tutorials/document-classification-tribuo-v4.ipynb
comment: ## DO NOT EDIT THIS FILE. IT IS COPIED FROM THE TRIBUO DOC. EDIT IT THERE. ##
---
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Document-Classification">Document Classification<a class="anchor-link" href="#Document-Classification">&#182;</a></h1><p>This tutorial will show how to perform document classification in Tribuo, using a variety of different methods to extract features from the text. We'll use the venerable <a href="http://qwone.com/~jason/20Newsgroups/">20-newsgroups dataset</a> where the task is to predict what newsgroup a particular post is from, though this tutorial would be equally applicable to any document classification task (including tasks like sentiment analysis). We're going to train a simple logistic regression with fixed hyperparameters using a variety of feature extraction methods. The aim is to show how to extract features from text rather than focusing on the performance, as using a more powerful model like XGBoost, or performing hyperparameter optimization on the logisitic regression will likely improve the performance of all the feature extraction techniques.</p>
<h1 id="Setup">Setup<a class="anchor-link" href="#Setup">&#182;</a></h1><p>You'll need a copy of the 20 newsgroups dataset, so first download and unpack it:</p>

<pre><code>wget http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz
mkdir 20news
cd 20news
tar -zxf ../20news-bydate.tar.gz</code></pre>
<p>This leaves you with two directories <code>20news-bydate-train</code> and <code>20news-bydate-test</code>, which contain the standard train and test split for this data.</p>
<p>20 newsgroups comes in a fairly standard format, the dataset is represented by a set of directories where the directory name is the class label, and the directory contains a collection of documents with one document in each file. Each file is a single Usenet post. For the purposes of this tutorial, we'll use the subject and body of the post as the input text for classification.</p>
<p>Here's an example:</p>

<pre><code>$ ls 20news-bydate-train/
alt.atheism/               comp.sys.mac.hardware/  rec.motorcycles/     sci.electronics/         talk.politics.guns/
comp.graphics/             comp.windows.x/         rec.sport.baseball/  sci.med/                 talk.politics.mideast/
comp.os.ms-windows.misc/   misc.forsale/           rec.sport.hockey/    sci.space/               talk.politics.misc/
comp.sys.ibm.pc.hardware/  rec.autos/              sci.crypt/           soc.religion.christian/  talk.religion.misc/
$ ls 20news-bydate-train/comp.graphics/
37261  37949  38233  38270  38305  38344  38381  38417  38454  38489  38525  38562  38598  38633  38668  38703  38739
37913  37950  38234  38271  38306  38346  38382  38418  38455  38490  38526  38563  38599  38634  38669  38704  38740
37914  37951  38235  38272  38307  38347  38383  38420  38456  38491  38527  38564  38600  38635  38670  38705  38741
37915  37952  38236  38273  38308  38348  38384  38421  38457  38492  38528  38565  38601  38636  38671  38706  38742
...</code></pre>
<p>As this is a pretty common format, Tribuo has a specific <code>DataSource</code> which can be used to read in this sort of data, <code>org.tribuo.data.text.DirectoryFileSource</code>.</p>
<p>We're going to use the classification experiments jar, along with the ONNX jar which provides support for loading in contextual word embedding models like <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">BERT</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="o">%</span><span class="n">jars</span><span class="w"> </span><span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">classification</span><span class="o">-</span><span class="n">experiments</span><span class="o">-</span><span class="mf">4.3.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span><span class="w"></span>
<span class="o">%</span><span class="n">jars</span><span class="w"> </span><span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">onnx</span><span class="o">-</span><span class="mf">4.3.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll also need a selection of imports from the <code>org.tribuo.data.text</code> package, along with the usual imports from <code>org.tribuo</code> and <code>org.tribuo.classification</code> we use when working with classification tasks. We'll load in the BERT support from the <code>org.tribuo.interop.onnx.extractors</code> package. Tribuo's BERT support loads in models and tokenizers from <a href="https://huggingface.co/transformers/">HuggingFace's Transformer</a> package, and can be easily extended to support non-BERT models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Collections</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">java.nio.file.Paths</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">com.oracle.labs.mlrg.olcut.provenance.ProvenanceUtil</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">com.oracle.labs.mlrg.olcut.util.Pair</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.data.text.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.data.text.impl.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.dataset.MinimumCardinalityDataset</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.classification.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.classification.evaluation.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.classification.sgd.linear.LinearSGDTrainer</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.classification.sgd.objectives.LogMulticlass</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.interop.onnx.extractors.BERTFeatureExtractor</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.math.optimisers.AdaGrad</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.transform.*</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.transform.transformations.IDFTransformation</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.util.tokens.universal.UniversalTokenizer</span><span class="p">;</span><span class="w"></span>
<span class="kn">import</span><span class="w"> </span><span class="nn">org.tribuo.util.Util</span><span class="p">;</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll instantiate a few classes that we'll use throughout this tutorial, the label factory, the evaluator and the paths to the train and test data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">labelFactory</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">LabelFactory</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">LabelEvaluator</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">trainPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;.&quot;</span><span class="p">,</span><span class="s">&quot;20news&quot;</span><span class="p">,</span><span class="s">&quot;20news-bydate-train&quot;</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">testPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;.&quot;</span><span class="p">,</span><span class="s">&quot;20news&quot;</span><span class="p">,</span><span class="s">&quot;20news-bydate-test&quot;</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Extracting-features-from-text">Extracting features from text<a class="anchor-link" href="#Extracting-features-from-text">&#182;</a></h1><p>Much of the work of machine learning is in presenting an appropriate representation of the data to the model. This is especially true when working with text data, as there is a plethora of approaches for converting text into the numbers that ML algorithms operate on. The <code>DirectoryFileSource</code> allows the user to choose the feature extraction, as it requires a <code>TextFeatureExtractor</code> which converts the <code>String</code> representing the input text into a Tribuo <code>Example</code>. We'll cover several different implementations of the <code>TextFeatureExtractor</code> interface in this tutorial, and we expect that users will implement it in their own classes to cope with specific feature extraction requirements.</p>
<p>We'll start with the simplest approach, a "bag of words", where each document is represented by the counts of the words in that document. This means the feature space is equal to the number of words, and most documents only have a positive value for a small number of words (as most words don't appear in any given document). This is particularly well suited to Tribuo's sparse vector representation of examples, and this suitability for NLP tasks is the reason that Tribuo is designed this way. Of course, first we'll need to tell the extractor what a word is, and for this we use a <code>Tokenizer</code>. Tokenizers split up a <code>String</code> into a stream of tokens. Tribuo provides several basic tokenizers, and an interface for tokenization. We're going to use Tribuo's <code>UniversalTokenizer</code> which is descended from tokenizers developed at Sun Labs in the 90s, and used in a variety of Sun products since that time. First we'll use a strict bag of words where each feature takes the value <code>1</code> if that word is present in the document, and <code>0</code> otherwise. We'll use Tribuo's <code>BasicPipeline</code> which can convert <code>String</code>s into features, and pass it to the basic <code>TextFeatureExtractor</code> implementation, helpfully called <code>TextFeatureExtractorImpl</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">tokenizer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">UniversalTokenizer</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowPipeline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">BasicPipeline</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowExtractor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TextFeatureExtractorImpl</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">bowPipeline</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're now almost ready to make our train and test data sources, and load in the data. The <code>DirectoryFileSource</code> also accepts an array of <code>DocumentPreprocessor</code>s which can be used to transform the text before feature extraction takes place. We're going to use a specific preprocessor (<code>NewsPreprocessor</code>) which standardises the 20 newsgroups data by stripping out the mail headers and returning only the subject and the body of the email. We'll also lowercase all the text using the <code>CasingPreprocessor</code> to slightly reduce the space we're working in. In general the preprocessors are dataset and task specific, which is why Tribuo doesn't ship with many implementations as in most cases users will need to write one from scratch for their specific task.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">newsProc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NewsPreprocessor</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">lowercase</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">CasingPreprocessor</span><span class="p">(</span><span class="n">CasingPreprocessor</span><span class="p">.</span><span class="na">CasingOperation</span><span class="p">.</span><span class="na">LOWERCASE</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll make a helper function to load the data sources and create the datasets. We're also going to restrict the test dataset so it only contains valid examples, as 20 newsgroups has some test examples that share no words with the train examples (and so have no features we could use to make predictions with).</p>
<p>Let's check our datasets and see if everything has loaded in correctly.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">public</span><span class="w"> </span><span class="n">Pair</span><span class="o">&lt;</span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">,</span><span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="nf">mkDatasets</span><span class="p">(</span><span class="n">String</span><span class="w"> </span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">TextFeatureExtractor</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="w"> </span><span class="n">extractor</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="n">trainSource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">DirectoryFileSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">trainPath</span><span class="p">,</span><span class="n">labelFactory</span><span class="p">,</span><span class="n">extractor</span><span class="p">,</span><span class="n">newsProc</span><span class="p">,</span><span class="n">lowercase</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="n">testSource</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">DirectoryFileSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">testPath</span><span class="p">,</span><span class="n">labelFactory</span><span class="p">,</span><span class="n">extractor</span><span class="p">,</span><span class="n">newsProc</span><span class="p">,</span><span class="n">lowercase</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="n">trainDS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">trainSource</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="n">testDS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">ImmutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">testSource</span><span class="p">,</span><span class="n">trainDS</span><span class="p">.</span><span class="na">getFeatureIDMap</span><span class="p">(),</span><span class="n">trainDS</span><span class="p">.</span><span class="na">getOutputIDInfo</span><span class="p">(),</span><span class="kc">true</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot; training data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">trainDS</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">trainDS</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">trainDS</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
<span class="w">    </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s">&quot; testing data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">testDS</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">testDS</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">testDS</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Pair</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">trainDS</span><span class="p">,</span><span class="n">testDS</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kd">var</span><span class="w"> </span><span class="n">bowPair</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mkDatasets</span><span class="p">(</span><span class="s">&quot;bow&quot;</span><span class="p">,</span><span class="n">bowExtractor</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>bow training data size = 11314, number of features = 122024, number of classes = 20
bow testing data size = 7532, number of features = 122024, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We've loaded in 11,314 training documents containing 122,024 unique words and 7,532 test documents, each with the expected 20 classes.</p>
<p>Now we're ready to train a model. Let's start with a simple logistic regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">lrTrainer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">LinearSGDTrainer</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">LogMulticlass</span><span class="p">(),</span><span class="k">new</span><span class="w"> </span><span class="n">AdaGrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.001</span><span class="p">),</span><span class="mi">5</span><span class="p">,</span><span class="mi">42</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">bowPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on BoW features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">bowStartTime</span><span class="p">,</span><span class="n">bowEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bowEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">bowModel</span><span class="p">,</span><span class="n">bowPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">bowEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on BoW features took (00:00:10:110)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         346          52          93       0.869       0.788       0.827
rec.autos                          396         349          47          79       0.881       0.815       0.847
talk.religion.misc                 251         154          97         109       0.614       0.586       0.599
comp.windows.x                     395         293         102          66       0.742       0.816       0.777
rec.sport.baseball                 397         368          29          45       0.927       0.891       0.909
talk.politics.mideast              376         286          90          22       0.761       0.929       0.836
comp.graphics                      389         285         104         163       0.733       0.636       0.681
comp.sys.ibm.pc.hardware           392         291         101         165       0.742       0.638       0.686
sci.med                            396         299          97          60       0.755       0.833       0.792
comp.os.ms-windows.misc            394         241         153          74       0.612       0.765       0.680
sci.crypt                          396         346          50          45       0.874       0.885       0.879
comp.sys.mac.hardware              385         294          91          85       0.764       0.776       0.770
talk.politics.misc                 310         170         140          96       0.548       0.639       0.590
rec.motorcycles                    398         370          28          25       0.930       0.937       0.933
misc.forsale                       390         344          46          67       0.882       0.837       0.859
sci.electronics                    393         269         124         112       0.684       0.706       0.695
rec.sport.hockey                   399         371          28          18       0.930       0.954       0.942
sci.space                          394         324          70          44       0.822       0.880       0.850
alt.atheism                        319         240          79          97       0.752       0.712       0.732
talk.politics.guns                 364         308          56         119       0.846       0.721       0.779
Total                            7,532       5,948       1,584       1,584
Accuracy                                                                         0.790
Micro Average                                                                    0.790       0.790       0.790
Macro Average                                                                    0.783       0.787       0.783
Balanced Error Rate                                                              0.217
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We got a macro F1 score of 79.0%, which is a fairly good starting point and it's roughly what other linear models get on this task (e.g., scikit-learn's text classification tutorial gets 76.9% macro F1 when using a similar multinomial Naive Bayes model).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Term-counting">Term counting<a class="anchor-link" href="#Term-counting">&#182;</a></h2><p>This simple Bag of Words approach discards a lot of information about the documents, as we're ignoring how many times the word or n-gram appears in the document (also known in information retrieval circles as the Term Frequency or TF). Let's swap the <code>BasicPipeline</code> for a <code>TokenPipeline</code> which supports term counting via a constructor flag.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">unigramPipeline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TokenPipeline</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">unigramExtractor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TextFeatureExtractorImpl</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">unigramPipeline</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">unigramPair</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mkDatasets</span><span class="p">(</span><span class="s">&quot;unigram&quot;</span><span class="p">,</span><span class="n">unigramExtractor</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>unigram training data size = 11314, number of features = 122024, number of classes = 20
unigram testing data size = 7532, number of features = 122024, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the number of documents and number of features are still the same, all that's different is the feature values within each document. Let's build another logistic regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">unigramStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">unigramModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">unigramPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">unigramEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on Unigram features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">unigramStartTime</span><span class="p">,</span><span class="n">unigramEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">unigramEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">unigramModel</span><span class="p">,</span><span class="n">unigramPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">unigramEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on Unigram features took (00:00:12:351)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         341          57          90       0.857       0.791       0.823
rec.autos                          396         357          39          69       0.902       0.838       0.869
talk.religion.misc                 251         155          96         122       0.618       0.560       0.587
comp.windows.x                     395         291         104          59       0.737       0.831       0.781
rec.sport.baseball                 397         361          36          43       0.909       0.894       0.901
talk.politics.mideast              376         274         102          27       0.729       0.910       0.809
comp.graphics                      389         288         101         114       0.740       0.716       0.728
comp.sys.ibm.pc.hardware           392         279         113         141       0.712       0.664       0.687
sci.med                            396         310          86          73       0.783       0.809       0.796
comp.os.ms-windows.misc            394         263         131          98       0.668       0.729       0.697
sci.crypt                          396         344          52          54       0.869       0.864       0.866
comp.sys.mac.hardware              385         301          84          82       0.782       0.786       0.784
talk.politics.misc                 310         168         142         121       0.542       0.581       0.561
rec.motorcycles                    398         365          33          31       0.917       0.922       0.919
misc.forsale                       390         321          69          70       0.823       0.821       0.822
sci.electronics                    393         282         111         117       0.718       0.707       0.712
rec.sport.hockey                   399         380          19          29       0.952       0.929       0.941
sci.space                          394         323          71          35       0.820       0.902       0.859
alt.atheism                        319         246          73         105       0.771       0.701       0.734
talk.politics.guns                 364         300          64         103       0.824       0.744       0.782
Total                            7,532       5,949       1,583       1,583
Accuracy                                                                         0.790
Micro Average                                                                    0.790       0.790       0.790
Macro Average                                                                    0.784       0.785       0.783
Balanced Error Rate                                                              0.216
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We see that the logistic regression trained on unigrams gets about 79% accuracy, pretty much the same as the BoW baseline, and takes about the same amount of time to run. Both of these make sense, as the term count isn't necessarily that useful in this particular dataset, and we didn't change the number of features overall or inside each example by using term counting.</p>
<h2 id="N-grams-as-features">N-grams as features<a class="anchor-link" href="#N-grams-as-features">&#182;</a></h2><p>Let's try a little more complicated feature extractor. The natural step from unigrams is to include word pairs (or bigrams) and count the occurrence of those. This allows us to get simple negations (e.g., "not bad" rather than "not" and "bad") along with places like "New York" rather than "new" and "york". In Tribuo this is as straightforward as telling the token pipeline we'd like bigrams.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">bigramPipeline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TokenPipeline</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bigramExtractor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TextFeatureExtractorImpl</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">bigramPipeline</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bigramPair</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mkDatasets</span><span class="p">(</span><span class="s">&quot;bigram&quot;</span><span class="p">,</span><span class="n">bigramExtractor</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>bigram training data size = 11314, number of features = 1143035, number of classes = 20
bigram testing data size = 7532, number of features = 1143035, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the feature space has massively increased due to the presence of bigram features, we've now got 1.1 million features from the same 11,314 documents.</p>
<p>Now to train another logistic regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">bigramStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bigramModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">bigramPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bigramEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on Bigram features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">bigramStartTime</span><span class="p">,</span><span class="n">bigramEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bigramEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">bigramModel</span><span class="p">,</span><span class="n">bigramPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">bigramEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on Bigram features took (00:00:32:704)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         328          70          38       0.824       0.896       0.859
rec.autos                          396         328          68          53       0.828       0.861       0.844
talk.religion.misc                 251         165          86          93       0.657       0.640       0.648
comp.windows.x                     395         296          99          72       0.749       0.804       0.776
rec.sport.baseball                 397         357          40          51       0.899       0.875       0.887
talk.politics.mideast              376         292          84          38       0.777       0.885       0.827
comp.graphics                      389         288         101         205       0.740       0.584       0.653
comp.sys.ibm.pc.hardware           392         281         111         168       0.717       0.626       0.668
sci.med                            396         289         107          60       0.730       0.828       0.776
comp.os.ms-windows.misc            394         262         132          86       0.665       0.753       0.706
sci.crypt                          396         343          53          65       0.866       0.841       0.853
comp.sys.mac.hardware              385         289          96         110       0.751       0.724       0.737
talk.politics.misc                 310         176         134          63       0.568       0.736       0.641
rec.motorcycles                    398         366          32          51       0.920       0.878       0.898
misc.forsale                       390         341          49          71       0.874       0.828       0.850
sci.electronics                    393         240         153          67       0.611       0.782       0.686
rec.sport.hockey                   399         366          33          28       0.917       0.929       0.923
sci.space                          394         334          60          51       0.848       0.868       0.858
alt.atheism                        319         256          63         137       0.803       0.651       0.719
talk.politics.guns                 364         300          64         128       0.824       0.701       0.758
Total                            7,532       5,897       1,635       1,635
Accuracy                                                                         0.783
Micro Average                                                                    0.783       0.783       0.783
Macro Average                                                                    0.778       0.784       0.778
Balanced Error Rate                                                              0.222
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our performance decreased a little when using bigrams to 78%, and the runtime increased from 12s to 32s. This is because despite there being more information in the features, there are also many, many more features making it easier to confuse this simple linear model plus each example takes longer to process due to the greatly increased number of features. We could look at using a more complex model like boosted trees to exploit this additional information which may increase the performance back above our baseline. We could further increase number of n-gram features but we'll start to see diminishing returns even with more powerful models as the dimensionality of the feature space increases without a commensurate increase in training data.</p>
<h2 id="TFIDF-vectors">TFIDF vectors<a class="anchor-link" href="#TFIDF-vectors">&#182;</a></h2><p>One other factor is that the count of some words isn't usually that helpful, as most documents include "a", "the", "and" many times which just isn't a useful signal. A popular way to deal with this is to scale the term frequencies (i.e., the n-gram counts) by the Inverse Document Frequency (or IDF), producing TF-IDF vectors. In Tribuo the IDF is a transformation which is applied separately to the dataset after it's constructed, as it uses aggregate information from the whole dataset which isn't available until all the examples have been loaded in. Let's see how that affects performance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="c1">// Create a transformation map that contains a single IDFTransformation to apply to every feature</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">trMap</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TransformationMap</span><span class="p">(</span><span class="n">Collections</span><span class="p">.</span><span class="na">singletonList</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">IDFTransformation</span><span class="p">()));</span><span class="w"></span>
<span class="c1">// Copy out the datasets.</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tfidfTrain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MutableDataset</span><span class="p">.</span><span class="na">createDeepCopy</span><span class="p">(</span><span class="n">bigramPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tfidfTest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MutableDataset</span><span class="p">.</span><span class="na">createDeepCopy</span><span class="p">(</span><span class="n">bigramPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="c1">// Fit the IDF transformation and apply it to the data</span><span class="w"></span>
<span class="c1">// We add the implicit zero features (i.e. the words not present in each document)</span><span class="w"></span>
<span class="c1">// to get the correct estimate of the IDF.</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">transformers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tfidfTrain</span><span class="p">.</span><span class="na">createTransformers</span><span class="p">(</span><span class="n">trMap</span><span class="p">,</span><span class="kc">true</span><span class="p">);</span><span class="w"></span>
<span class="n">tfidfTrain</span><span class="p">.</span><span class="na">transform</span><span class="p">(</span><span class="n">transformers</span><span class="p">);</span><span class="w"></span>
<span class="n">tfidfTest</span><span class="p">.</span><span class="na">transform</span><span class="p">(</span><span class="n">transformers</span><span class="p">);</span><span class="w"></span>
<span class="c1">// Print the dataset statistics    </span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;tf-idf training data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">tfidfTrain</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">tfidfTrain</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">tfidfTrain</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;tf-idf testing data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">tfidfTest</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">tfidfTest</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">tfidfTest</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>tf-idf training data size = 11314, number of features = 1143035, number of classes = 20
tf-idf testing data size = 7532, number of features = 316757, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Creating TF-IDF vectors didn't change the number of features, we still have 1.1 million features in the training set, but it has made the feature values more useful. The irrelevant "the" features will have a small value because while they may have a high term frequency, they are also present in every document so they have a high document frequency, so when we divide the two values it'll end up small.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">tfidfStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tfidfModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">tfidfTrain</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tfidfEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on TF-IDF features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">tfidfStartTime</span><span class="p">,</span><span class="n">tfidfEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tfidfEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">tfidfModel</span><span class="p">,</span><span class="n">tfidfTest</span><span class="p">);</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">tfidfEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on TF-IDF features took (00:00:33:661)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         329          69          83       0.827       0.799       0.812
rec.autos                          396         338          58          63       0.854       0.843       0.848
talk.religion.misc                 251         171          80          83       0.681       0.673       0.677
comp.windows.x                     395         317          78          86       0.803       0.787       0.794
rec.sport.baseball                 397         356          41          31       0.897       0.920       0.908
talk.politics.mideast              376         310          66          28       0.824       0.917       0.868
comp.graphics                      389         273         116         114       0.702       0.705       0.704
comp.sys.ibm.pc.hardware           392         268         124         128       0.684       0.677       0.680
sci.med                            396         325          71         143       0.821       0.694       0.752
comp.os.ms-windows.misc            394         263         131          77       0.668       0.774       0.717
sci.crypt                          396         338          58          60       0.854       0.849       0.851
comp.sys.mac.hardware              385         285         100          69       0.740       0.805       0.771
talk.politics.misc                 310         181         129          55       0.584       0.767       0.663
rec.motorcycles                    398         362          36          47       0.910       0.885       0.897
misc.forsale                       390         331          59          64       0.849       0.838       0.843
sci.electronics                    393         251         142          84       0.639       0.749       0.690
rec.sport.hockey                   399         369          30          15       0.925       0.961       0.943
sci.space                          394         350          44         113       0.888       0.756       0.817
alt.atheism                        319         251          68          80       0.787       0.758       0.772
talk.politics.guns                 364         315          49         126       0.865       0.714       0.783
Total                            7,532       5,983       1,549       1,549
Accuracy                                                                         0.794
Micro Average                                                                    0.794       0.794       0.794
Macro Average                                                                    0.790       0.794       0.790
Balanced Error Rate                                                              0.210
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using TF-IDF features has roughly the same accuracy as bigrams, so it may be that these features aren't something the linear model can easily operate on on this dataset, but in general the TF-IDF transformation is a useful one when working with text documents.</p>
<h2 id="Feature-hashing">Feature hashing<a class="anchor-link" href="#Feature-hashing">&#182;</a></h2><p>A popular technique for dealing with large feature spaces is feature hashing. This is where the features are mapped back down to a smaller space using a hash function. It induces collisions between the features, so the model might treat "New York" and "San Francisco" as the same feature, but the collisions are generated essentially at random based on the hash function which provides a strong regularising effect which can improve performance while making things run faster and use less memory.</p>
<p>To use feature hashing in Tribuo simply pass a hash dimension to the <code>TokenPipeline</code> on construction. We'll map everything down to 50,000 features, which is around 5% of the original number and see how that affects the model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">hashPipeline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TokenPipeline</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span><span class="w"> </span><span class="mi">50000</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">hashExtractor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">TextFeatureExtractorImpl</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">hashPipeline</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">hashPair</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mkDatasets</span><span class="p">(</span><span class="s">&quot;hash-100k&quot;</span><span class="p">,</span><span class="n">hashExtractor</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>hash-100k training data size = 11314, number of features = 50000, number of classes = 20
hash-100k testing data size = 7532, number of features = 50000, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected we still have the same number of training &amp; test examples, but now there are only 50,000 features. Let's build another logistic regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">hashStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">hashModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">hashPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">hashEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on hashed features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">hashStartTime</span><span class="p">,</span><span class="n">hashEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">hashEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">hashModel</span><span class="p">,</span><span class="n">hashPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">hashEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on hashed features took (00:00:18:148)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         293         105          77       0.736       0.792       0.763
rec.autos                          396         304          92          75       0.768       0.802       0.785
talk.religion.misc                 251         159          92         177       0.633       0.473       0.542
comp.windows.x                     395         293         102          76       0.742       0.794       0.767
rec.sport.baseball                 397         343          54         108       0.864       0.761       0.809
talk.politics.mideast              376         267         109          34       0.710       0.887       0.789
comp.graphics                      389         254         135         121       0.653       0.677       0.665
comp.sys.ibm.pc.hardware           392         253         139         138       0.645       0.647       0.646
sci.med                            396         281         115         109       0.710       0.721       0.715
comp.os.ms-windows.misc            394         240         154          98       0.609       0.710       0.656
sci.crypt                          396         330          66          81       0.833       0.803       0.818
comp.sys.mac.hardware              385         271         114         117       0.704       0.698       0.701
talk.politics.misc                 310         174         136         160       0.561       0.521       0.540
rec.motorcycles                    398         336          62          41       0.844       0.891       0.867
misc.forsale                       390         334          56          83       0.856       0.801       0.828
sci.electronics                    393         245         148         132       0.623       0.650       0.636
rec.sport.hockey                   399         343          56          32       0.860       0.915       0.886
sci.space                          394         306          88          75       0.777       0.803       0.790
alt.atheism                        319         225          94         105       0.705       0.682       0.693
talk.politics.guns                 364         300          64         142       0.824       0.679       0.744
Total                            7,532       5,551       1,981       1,981
Accuracy                                                                         0.737
Micro Average                                                                    0.737       0.737       0.737
Macro Average                                                                    0.733       0.735       0.732
Balanced Error Rate                                                              0.267
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The performance dropped a little here, but the model has less than a tenth of the parameters compared to the bigram model, making it faster and much smaller at inference time, and it took around 66% of the time to train. In many cases dropping a couple of points of accuracy for a model that is 20x smaller and substantially faster is a worthwhile tradeoff, but as with most machine learning tasks this depends on the problem you're solving and where you're deploying the model. Tuning the hashing dimension and the trainer parameters will likely produce a model with similar accuracy at greatly reduced computational cost.</p>
<h2 id="Trimming-out-infrequent-features">Trimming out infrequent features<a class="anchor-link" href="#Trimming-out-infrequent-features">&#182;</a></h2><p>We can also directly trim out infrequently occuring features. If a feature doesn't occur very frequently then we're not likely to estimate it's weights properly as we've not seen it very often. Then if it occurs frequently in the test dataset it can confuse the model (this is a form of overfitting to the training data). Let's take the TF-IDF dataset and remove all the bigrams that occur fewer than 5 times.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">minCardTrain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">MinimumCardinalityDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">tfidfTrain</span><span class="p">,</span><span class="mi">5</span><span class="p">);</span><span class="w"></span>
<span class="c1">// This call creates a copy of bigramTest, removing all the </span><span class="w"></span>
<span class="c1">// features not found in bigramTrain&#39;s feature and output maps</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">minCardTest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ImmutableDataset</span><span class="p">.</span><span class="na">copyDataset</span><span class="p">(</span><span class="n">tfidfTest</span><span class="p">,</span><span class="n">minCardTrain</span><span class="p">.</span><span class="na">getFeatureIDMap</span><span class="p">(),</span><span class="n">minCardTrain</span><span class="p">.</span><span class="na">getOutputIDInfo</span><span class="p">());</span><span class="w"></span>
<span class="c1">// Print the dataset statistics    </span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;Minimum cardinality training data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">minCardTrain</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">minCardTrain</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">minCardTrain</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;Minimum cardinality testing data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">minCardTest</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">minCardTest</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">minCardTest</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Minimum cardinality training data size = 11314, number of features = 109743, number of classes = 20
Minimum cardinality testing data size = 7532, number of features = 109743, number of classes = 20
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that's removed about 90% of the features, so let's try our simple model on it again.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">minCardStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">minCardModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">minCardTrain</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">minCardEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training the model on trimmed TF-IDF features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">minCardStartTime</span><span class="p">,</span><span class="n">minCardEndTime</span><span class="p">));</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">minCardEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">minCardModel</span><span class="p">,</span><span class="n">minCardTest</span><span class="p">);</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">minCardEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training the model on trimmed TF-IDF features took (00:00:14:750)

Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         346          52         128       0.869       0.730       0.794
rec.autos                          396         314          82          68       0.793       0.822       0.807
talk.religion.misc                 251         162          89         121       0.645       0.572       0.607
comp.windows.x                     395         275         120          55       0.696       0.833       0.759
rec.sport.baseball                 397         333          64          26       0.839       0.928       0.881
talk.politics.mideast              376         295          81          28       0.785       0.913       0.844
comp.graphics                      389         280         109         173       0.720       0.618       0.665
comp.sys.ibm.pc.hardware           392         277         115         186       0.707       0.598       0.648
sci.med                            396         304          92         127       0.768       0.705       0.735
comp.os.ms-windows.misc            394         239         155          72       0.607       0.768       0.678
sci.crypt                          396         343          53          70       0.866       0.831       0.848
comp.sys.mac.hardware              385         259         126          60       0.673       0.812       0.736
talk.politics.misc                 310         193         117          68       0.623       0.739       0.676
rec.motorcycles                    398         359          39          65       0.902       0.847       0.873
misc.forsale                       390         339          51          84       0.869       0.801       0.834
sci.electronics                    393         246         147         103       0.626       0.705       0.663
rec.sport.hockey                   399         367          32          16       0.920       0.958       0.939
sci.space                          394         335          59          86       0.850       0.796       0.822
alt.atheism                        319         237          82          63       0.743       0.790       0.766
talk.politics.guns                 364         310          54         120       0.852       0.721       0.781
Total                            7,532       5,813       1,719       1,719
Accuracy                                                                         0.772
Micro Average                                                                    0.772       0.772       0.772
Macro Average                                                                    0.768       0.774       0.768
Balanced Error Rate                                                              0.232
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As with the feature hashing above, this model trains more quickly because there is less data to process, but the speed improvement is more substantial as the number of features in each example is lower (because the hashing produces a denser example than trimming out infrequent features). Performance dropped slightly as compared to the TF-IDF model, but again it is around 10% of the parameters, with a corresponding reduction in memory and runtime in inference and training. Performance is improved over the hashing as we're not colliding features at random, we're simply removing ones which are infrequent. If a feature is infrequent we probably can't estimate the weight for it very well so it helps remove some of the noise.</p>
<p>Choosing which one of feature hashing and trimming out infrequent features to apply is problem dependent. Feature hashing can work in denser feature spaces than trimming infrequent features, but both still require some amount of sparsity in the problem to have any useful effect. With text datasets then trimming the infrequent words/features is usually helpful.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word-embeddings">Word embeddings<a class="anchor-link" href="#Word-embeddings">&#182;</a></h2><p>All the approaches described above have no notion of word similarity, they rely upon exactly the same words with the same spelling appearing in the training and test documents, when in practice word similarity is likely to be very useful information for the classifier because no two documents use exactly the same phrasing. For example, the unigrams "excellent" and "fantastic" are equally dissimilar to an n-gram model, when in fact those words are quite similar in meaning. Adding notions of word similarity to ML models usually means embedding each word into some vector space, then words with similar meanings can be close in the vector space, and words with dissimilar or opposite meanings are far apart. There are many popular word embedding algorithms, like <a href="https://arxiv.org/abs/1301.3781">Word2Vec</a>, <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a> or <a href="https://fasttext.cc/">FastText</a> which build embeddings on a corpus of text that can then be used in downstream tasks. Tribuo doesn't have a class which can directly load those word vectors, as they all come in different file formats, but it's pretty straightforward to build a <code>TextFeatureExtractor</code> that will tokenize the input text, look up each word or n-gram in the vector space and then average them across the input (it took us about an afternoon to build one for our internal word2vec style word vector research file format). If there is interest from the community in supporting a specific word vector file format, we're happy to accept PRs that add the support.</p>
<p>While these more traditional forms of word vector are very powerful, as they are precomputed they treat each word the same no matter the context it appears in. For example "bank" could mean a river bank, or a financial institution, but a word2vec vector has to contain both meanings because it doesn't know the <em>context</em> the word is present in, i.e., the rest of the sentence. This led to the rise of <em>contextual</em> word embeddings, which produce a vector for each word based on the whole input sequence. The most popular of these embeddings are based on the <a href="https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Transformer</a> architecture, usually a variant of Google's <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">BERT</a> model.</p>
<h2 id="Using-BERT-embeddings">Using BERT embeddings<a class="anchor-link" href="#Using-BERT-embeddings">&#182;</a></h2><p>BERT is a multi-layer transformer network, which reads in a sentence and produces both an embedding of the sentence, along with embeddings for each wordpiece. A "wordpiece" is the token that BERT operates on, which is either a whole word, or a chunk of a word, emitted by the wordpiece tokenizer. The word chunking algorithm is trained on a large corpus and allows common prefixes &amp; suffixes (e.g. "un", "ing") to be split off the words and to share state. We can use BERT to produce a single vector which represents the sentence or document and then use that vector as features in a downstream Tribuo classifier.</p>
<p>Tribuo works with BERT models that are stored in <a href="https://onnx.ai">ONNX format</a>, and can load in tokenizers produced by <a href="https://huggingface.co/transformers/">HuggingFace Transformers</a>. That package also helpfully provides a Python script to convert BERT models from HuggingFace format into ONNX format for deployment. We provide a <code>TextFeatureExtractor</code> implementation called <code>BERTFeatureExtractor</code> which can produce sentence embeddings out by passing the text through a BERT model. Tribuo uses Microsoft's <a href="https://www.onnxruntime.ai/">ONNX Runtime</a> to load the model, and has it's own implementation of the Wordpiece tokenization algorithm, along with the necessary glue to produce tokens in the format that BERT expects. One downside of BERT models is that they have a maximum document length that they can process, usually 512 wordpieces. This is configurable in Tribuo's extractor, but if you set the maximum length to be longer than the sequences the model was trained on then the performance is likely to suffer (or the computation may fail depending on how that specific BERT model is implemented).</p>
<p>To follow along with this part of the tutorial you'll need to produce a BERT model in onnx format. To do that you'll need access to a Python 3 environment with HuggingFace and PyTorch or TensorFlow installed to export the model (the snippet below assumes PyTorch, change the <code>pt</code> to <code>tf</code> if you're using TensorFlow). Running the following snippet will produce a <code>bert-base-uncased.onnx</code> file that we can use for the rest of the tutorial. You'll need to run it in an empty directory due to the way HuggingFace's conversion script works.</p>

<pre><code>python -m transformers.convert_graph_to_onnx --framework pt --model bert-base-uncased bert-base-uncased.onnx</code></pre>
<p>You'll also need to download the <code>tokenizer.json</code> that goes with the BERT variant you are using, for <code>bert-base-uncased</code> that file is <a href="https://huggingface.co/bert-base-uncased/raw/main/tokenizer.json">here</a>. Assuming both of those files are now in the same directory as this tutorial, we can create the <code>BERTFeatureExtractor</code>. We're going to take the average token embedding across the whole input, as the <code>[CLS]</code> token which provides the sentence embedding  tends to perform poorly unless it is fine-tuned on your task.</p>
<p>Warning: this feature extraction step took more than a minute per newsgroup on a 2019 16" 6-core MacBook Pro (using the default settings of ONNX Runtime i.e., using a single thead on the CPU provider) so around 55 minutes to extract the full train and test datasets. Your mileage may vary, and your laptop may get quite warm. We recommend not running it while your laptop is actually on your lap. At the moment Tribuo's <code>TextFeatureExtractor</code> interface doesn't batch up the inputs, which limits the performance of contextual feature extractors. We'll look at expanding that interface to support batching in a future release. The session options used can be controlled by the <code>BERTFeatureExtractor.reconfigureOrtSession(SessionOptions options)</code> method, which allows the use of whatever configuration is supported by your ONNX Runtime jar.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">bertPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;./bert-base-uncased.onnx&quot;</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">tokenizerPath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;./tokenizer.json&quot;</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bert</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">BERTFeatureExtractor</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">labelFactory</span><span class="p">,</span><span class="w"></span>
<span class="w">                                      </span><span class="n">bertPath</span><span class="p">,</span><span class="w"></span>
<span class="w">                                      </span><span class="n">tokenizerPath</span><span class="p">,</span><span class="w"></span>
<span class="w">                                      </span><span class="n">BERTFeatureExtractor</span><span class="p">.</span><span class="na">OutputPooling</span><span class="p">.</span><span class="na">MEAN</span><span class="p">,</span><span class="w"></span>
<span class="w">                                      </span><span class="mi">256</span><span class="p">,</span><span class="w">  </span><span class="c1">// Maximum number of wordpiece tokens</span><span class="w"></span>
<span class="w">                                      </span><span class="kc">false</span><span class="w"> </span><span class="c1">// Use Nvidia GPUs for inference (if onnxruntime_gpu is on the classpath)</span><span class="w"></span>
<span class="w">                                      </span><span class="p">);</span><span class="w"></span>
<span class="w">                                      </span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertPair</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mkDatasets</span><span class="p">(</span><span class="s">&quot;bert&quot;</span><span class="p">,</span><span class="n">bert</span><span class="p">);</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Extracting features with BERT took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">bertStartTime</span><span class="p">,</span><span class="n">bertEndTime</span><span class="p">));</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>bert training data size = 11314, number of features = 768, number of classes = 20
bert testing data size = 7532, number of features = 768, number of classes = 20
Extracting features with BERT took (00:32:03:647)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note Tribuo's <code>BERTFeatureExtractor</code> can run the BERT embeddings on a GPU, but only if the onnxruntime_gpu jar is on the classpath. By default Tribuo pulls in the CPU only jar for maximum compatibility. As you can see from the time taken to extract the features, it's best to deploy BERT when you've got plenty of CPUs or fast GPUs.</p>
<p>Now we build a logistic regression on the dense feature space produced by BERT. These embeddings are dense 768 dimensional vectors, each document contains a value for each one of those dimensions. In Tribuo 4.1 we added optimisations to several of the models and trainers to improve their performance on the dense feature spaces produced by techniques like BERT.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">bertStartTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lrTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">bertPair</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertEndTime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training a LR on BERT features took &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">bertStartTime</span><span class="p">,</span><span class="n">bertEndTime</span><span class="p">));</span><span class="w"></span>
<span class="kd">var</span><span class="w"> </span><span class="n">bertEval</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labelEvaluator</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">bertModel</span><span class="p">,</span><span class="n">bertPair</span><span class="p">.</span><span class="na">getB</span><span class="p">());</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">bertEval</span><span class="p">);</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training a LR on BERT features took (00:00:03:802)
Class                                n          tp          fn          fp      recall        prec          f1
soc.religion.christian             398         367          31         114       0.922       0.763       0.835
rec.autos                          396         306          90          51       0.773       0.857       0.813
talk.religion.misc                 251          62         189          48       0.247       0.564       0.343
comp.windows.x                     395         305          90         186       0.772       0.621       0.688
rec.sport.baseball                 397         357          40          20       0.899       0.947       0.922
talk.politics.mideast              376         292          84          29       0.777       0.910       0.838
comp.graphics                      389         243         146         153       0.625       0.614       0.619
comp.sys.ibm.pc.hardware           392         190         202         111       0.485       0.631       0.548
sci.med                            396         332          64          53       0.838       0.862       0.850
comp.os.ms-windows.misc            394         202         192          92       0.513       0.687       0.587
sci.crypt                          396         306          90          74       0.773       0.805       0.789
comp.sys.mac.hardware              385         263         122         201       0.683       0.567       0.620
talk.politics.misc                 310         164         146         168       0.529       0.494       0.511
rec.motorcycles                    398         337          61         118       0.847       0.741       0.790
misc.forsale                       390         317          73          56       0.813       0.850       0.831
sci.electronics                    393         234         159         124       0.595       0.654       0.623
rec.sport.hockey                   399         380          19          21       0.952       0.948       0.950
sci.space                          394         338          56         104       0.858       0.765       0.809
alt.atheism                        319         200         119         175       0.627       0.533       0.576
talk.politics.guns                 364         278          86         161       0.764       0.633       0.692
Total                            7,532       5,473       2,059       2,059
Accuracy                                                                         0.727
Micro Average                                                                    0.727       0.727       0.727
Macro Average                                                                    0.715       0.722       0.712
Balanced Error Rate                                                              0.285
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We get around 71% accuracy using this standard BERT model, which might be due to it's training data of Wikipedia and books not overlapping well with the comparatively old newsgroup language. Fine tuning the BERT model on a large corpus of newsgroups could probably improve this, but the standard model is likely to work well for more well formed text like news articles or more formal documents. Alternatively it may be that the logistic regression we're training isn't sufficiently flexible to use the information in the BERT features, so it may be beneficial to use a more complex classifier like gradient boosted trees or a Multi-Layer Perceptron through Tribuo's TensorFlow interface.</p>
<p>Using different BERT versions can change the accuracy as there are variants fine-tuned for a wide variety of different tasks &amp; domains, and there are smaller versions like DistillBERT and TinyBERT which are useful for deploying models in constrained environments. However BERT based feature extractors will always be slower than the simpler BoW approaches described above, because they have to perform lots of floating point computations to compute the embedded feature values.</p>
<h1 id="Deploying-the-feature-extractors">Deploying the feature extractors<a class="anchor-link" href="#Deploying-the-feature-extractors">&#182;</a></h1><p>Similarly to when working with columnar data, the feature extractor used is recorded in the model provenance. We can see that for the BERT model here.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span><span class="w"> </span><span class="n">sourceProvenance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bertModel</span><span class="p">.</span><span class="na">getProvenance</span><span class="p">().</span><span class="na">getDatasetProvenance</span><span class="p">().</span><span class="na">getSourceProvenance</span><span class="p">();</span><span class="w"></span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">ProvenanceUtil</span><span class="p">.</span><span class="na">formattedProvenanceString</span><span class="p">(</span><span class="n">sourceProvenance</span><span class="p">));</span><span class="w"></span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>DirectoryFileSource(
	class-name = org.tribuo.data.text.DirectoryFileSource
	dataDir = /local/ExternalRepositories/tribuo/tutorials/20news/20news-bydate-train
	preprocessors = List[
		NewsPreprocessor(
					class-name = org.tribuo.data.text.impl.NewsPreprocessor
					host-short-name = DocumentPreprocessor
				)
		CasingPreprocessor(
					class-name = org.tribuo.data.text.impl.CasingPreprocessor
					op = LOWERCASE
					host-short-name = DocumentPreprocessor
				)
	]
	extractor = BERTFeatureExtractor(
			class-name = org.tribuo.interop.onnx.extractors.BERTFeatureExtractor
			useCUDA = false
			pooling = MEAN
			modelPath = /local/ExternalRepositories/tribuo/tutorials/bert-base-uncased.onnx
			tokenizerPath = /local/ExternalRepositories/tribuo/tutorials/tokenizer.json
			outputFactory = LabelFactory(
					class-name = org.tribuo.classification.LabelFactory
				)
			maxLength = 256
			host-short-name = FeatureExtractor
		)
	outputFactory = LabelFactory(
			class-name = org.tribuo.classification.LabelFactory
		)
	file-modified-time = 2003-03-18T07:24:55-05:00
	datasource-creation-time = 2022-10-07T12:14:14.770299736-04:00
)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This means that the model has recorded how the features were extracted, but the extraction process itself isn't part of the serialized model (which we wouldn't really want anyway as BERT models are hundreds of megabytes). So to use one of these models at inference time the feature extraction pipeline needs to be rebuilt from the configuration, in the same way we rebuilt the <code>RowProcessor</code> in the columnar tutorial.</p>
<p>Each of the different models trained in this tutorial has recorded the source provenance and it's associated <code>TextFeatureExtractor</code> configuration, meaning the models come with all the necessary information to infer the classes of new documents.</p>
<h1 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h1><p>We looked at a document classification task in Tribuo. As most of the work in NLP tends to be on featurising the data, we discussed several different ways of converting text into features for use in machine learning. We looked at Bag of Words models, using n-grams, term frequencies, TFIDF vectors, feature hashing and also looked at trimming large feature spaces based on the number of times we'd seen a feature. We also discussed word vector approaches, and showed how to use the popular contextual word embedding model, BERT, to extract features for document classification. It's worth noting all the models trained were simple logistic regressions, with no parameter tuning. Using a more powerful classifier like XGBoost, or performing hyperparameter tuning on the logistic regression will likely improve performance over the simple baselines presented here.</p>
<p>Tribuo's text processing framework is very flexible, and it's possible to insert your own code into each of the different classes by implementing <code>TextFeatureExtractor</code>, <code>TextPipeline</code> or even the <code>Tokenizer</code> yourself, while the provenance system ensures that you can always recover how your data was processed to ensure it matches at inference time.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

