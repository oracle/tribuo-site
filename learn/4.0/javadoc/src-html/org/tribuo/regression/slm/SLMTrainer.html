<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (24) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.tribuo.regression.slm, class: SLMTrainer">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../resource-files/stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Copyright (c) 2015-2020, Oracle and/or its affiliates. All rights reserved.</span>
<span class="source-line-no">003</span><span id="line-3"> *</span>
<span class="source-line-no">004</span><span id="line-4"> * Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="source-line-no">005</span><span id="line-5"> * you may not use this file except in compliance with the License.</span>
<span class="source-line-no">006</span><span id="line-6"> * You may obtain a copy of the License at</span>
<span class="source-line-no">007</span><span id="line-7"> *</span>
<span class="source-line-no">008</span><span id="line-8"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">011</span><span id="line-11"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">012</span><span id="line-12"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express implied.</span>
<span class="source-line-no">013</span><span id="line-13"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">014</span><span id="line-14"> * limitations under the License.</span>
<span class="source-line-no">015</span><span id="line-15"> */</span>
<span class="source-line-no">016</span><span id="line-16"></span>
<span class="source-line-no">017</span><span id="line-17">package org.tribuo.regression.slm;</span>
<span class="source-line-no">018</span><span id="line-18"></span>
<span class="source-line-no">019</span><span id="line-19">import com.oracle.labs.mlrg.olcut.config.Config;</span>
<span class="source-line-no">020</span><span id="line-20">import com.oracle.labs.mlrg.olcut.provenance.Provenance;</span>
<span class="source-line-no">021</span><span id="line-21">import org.tribuo.Dataset;</span>
<span class="source-line-no">022</span><span id="line-22">import org.tribuo.Example;</span>
<span class="source-line-no">023</span><span id="line-23">import org.tribuo.ImmutableFeatureMap;</span>
<span class="source-line-no">024</span><span id="line-24">import org.tribuo.ImmutableOutputInfo;</span>
<span class="source-line-no">025</span><span id="line-25">import org.tribuo.SparseTrainer;</span>
<span class="source-line-no">026</span><span id="line-26">import org.tribuo.WeightedExamples;</span>
<span class="source-line-no">027</span><span id="line-27">import org.tribuo.math.la.DenseVector;</span>
<span class="source-line-no">028</span><span id="line-28">import org.tribuo.math.la.SparseVector;</span>
<span class="source-line-no">029</span><span id="line-29">import org.tribuo.math.la.VectorTuple;</span>
<span class="source-line-no">030</span><span id="line-30">import org.tribuo.provenance.ModelProvenance;</span>
<span class="source-line-no">031</span><span id="line-31">import org.tribuo.provenance.TrainerProvenance;</span>
<span class="source-line-no">032</span><span id="line-32">import org.tribuo.provenance.impl.TrainerProvenanceImpl;</span>
<span class="source-line-no">033</span><span id="line-33">import org.tribuo.regression.Regressor;</span>
<span class="source-line-no">034</span><span id="line-34">import org.tribuo.util.Util;</span>
<span class="source-line-no">035</span><span id="line-35">import org.apache.commons.math3.linear.Array2DRowRealMatrix;</span>
<span class="source-line-no">036</span><span id="line-36">import org.apache.commons.math3.linear.ArrayRealVector;</span>
<span class="source-line-no">037</span><span id="line-37">import org.apache.commons.math3.linear.LUDecomposition;</span>
<span class="source-line-no">038</span><span id="line-38">import org.apache.commons.math3.linear.RealMatrix;</span>
<span class="source-line-no">039</span><span id="line-39">import org.apache.commons.math3.linear.RealVector;</span>
<span class="source-line-no">040</span><span id="line-40">import org.apache.commons.math3.linear.SingularMatrixException;</span>
<span class="source-line-no">041</span><span id="line-41"></span>
<span class="source-line-no">042</span><span id="line-42">import java.time.OffsetDateTime;</span>
<span class="source-line-no">043</span><span id="line-43">import java.util.ArrayList;</span>
<span class="source-line-no">044</span><span id="line-44">import java.util.Arrays;</span>
<span class="source-line-no">045</span><span id="line-45">import java.util.HashMap;</span>
<span class="source-line-no">046</span><span id="line-46">import java.util.HashSet;</span>
<span class="source-line-no">047</span><span id="line-47">import java.util.List;</span>
<span class="source-line-no">048</span><span id="line-48">import java.util.Map;</span>
<span class="source-line-no">049</span><span id="line-49">import java.util.Set;</span>
<span class="source-line-no">050</span><span id="line-50">import java.util.logging.Level;</span>
<span class="source-line-no">051</span><span id="line-51">import java.util.logging.Logger;</span>
<span class="source-line-no">052</span><span id="line-52"></span>
<span class="source-line-no">053</span><span id="line-53">/**</span>
<span class="source-line-no">054</span><span id="line-54"> * A trainer for a sparse linear regression model.</span>
<span class="source-line-no">055</span><span id="line-55"> * Uses sequential forward selection to construct the model. Optionally can</span>
<span class="source-line-no">056</span><span id="line-56"> * normalize the data first. Each output dimension is trained independently</span>
<span class="source-line-no">057</span><span id="line-57"> * with no shared regularization.</span>
<span class="source-line-no">058</span><span id="line-58"> */</span>
<span class="source-line-no">059</span><span id="line-59">public class SLMTrainer implements SparseTrainer&lt;Regressor&gt;, WeightedExamples {</span>
<span class="source-line-no">060</span><span id="line-60">    private static final Logger logger = Logger.getLogger(SLMTrainer.class.getName());</span>
<span class="source-line-no">061</span><span id="line-61"></span>
<span class="source-line-no">062</span><span id="line-62">    @Config(description="Maximum number of features to use.")</span>
<span class="source-line-no">063</span><span id="line-63">    protected int maxNumFeatures = -1;</span>
<span class="source-line-no">064</span><span id="line-64"></span>
<span class="source-line-no">065</span><span id="line-65">    @Config(description="Normalize the data first.")</span>
<span class="source-line-no">066</span><span id="line-66">    protected boolean normalize;</span>
<span class="source-line-no">067</span><span id="line-67"></span>
<span class="source-line-no">068</span><span id="line-68">    protected int trainInvocationCounter = 0;</span>
<span class="source-line-no">069</span><span id="line-69"></span>
<span class="source-line-no">070</span><span id="line-70">    /**</span>
<span class="source-line-no">071</span><span id="line-71">     * Constructs a trainer for a sparse linear model using sequential forward selection.</span>
<span class="source-line-no">072</span><span id="line-72">     *</span>
<span class="source-line-no">073</span><span id="line-73">     * @param normalize Normalizes the data first (i.e., removes the bias term).</span>
<span class="source-line-no">074</span><span id="line-74">     * @param maxNumFeatures The maximum number of features to select. Supply -1 to select all features.</span>
<span class="source-line-no">075</span><span id="line-75">     */</span>
<span class="source-line-no">076</span><span id="line-76">    public SLMTrainer(boolean normalize, int maxNumFeatures) {</span>
<span class="source-line-no">077</span><span id="line-77">        this.normalize = normalize;</span>
<span class="source-line-no">078</span><span id="line-78">        this.maxNumFeatures = maxNumFeatures;</span>
<span class="source-line-no">079</span><span id="line-79">    }</span>
<span class="source-line-no">080</span><span id="line-80"></span>
<span class="source-line-no">081</span><span id="line-81">    /**</span>
<span class="source-line-no">082</span><span id="line-82">     * Constructs a trainer for a sparse linear model using sequential forward selection.</span>
<span class="source-line-no">083</span><span id="line-83">     * &lt;p&gt;</span>
<span class="source-line-no">084</span><span id="line-84">     * Selects all the features.</span>
<span class="source-line-no">085</span><span id="line-85">     *</span>
<span class="source-line-no">086</span><span id="line-86">     * @param normalize Normalizes the data first (i.e., removes the bias term).</span>
<span class="source-line-no">087</span><span id="line-87">     */</span>
<span class="source-line-no">088</span><span id="line-88">    public SLMTrainer(boolean normalize) {</span>
<span class="source-line-no">089</span><span id="line-89">        this(normalize,-1);</span>
<span class="source-line-no">090</span><span id="line-90">    }</span>
<span class="source-line-no">091</span><span id="line-91"></span>
<span class="source-line-no">092</span><span id="line-92">    /**</span>
<span class="source-line-no">093</span><span id="line-93">     * For OLCUT.</span>
<span class="source-line-no">094</span><span id="line-94">     */</span>
<span class="source-line-no">095</span><span id="line-95">    protected SLMTrainer() {}</span>
<span class="source-line-no">096</span><span id="line-96"></span>
<span class="source-line-no">097</span><span id="line-97">    protected RealVector newWeights(SLMState state) {</span>
<span class="source-line-no">098</span><span id="line-98">        RealVector result = SLMTrainer.ordinaryLeastSquares(state.xpi,state.y);</span>
<span class="source-line-no">099</span><span id="line-99"></span>
<span class="source-line-no">100</span><span id="line-100">        if (result == null) {</span>
<span class="source-line-no">101</span><span id="line-101">            return null;</span>
<span class="source-line-no">102</span><span id="line-102">        } else {</span>
<span class="source-line-no">103</span><span id="line-103">            return state.unpack(result);</span>
<span class="source-line-no">104</span><span id="line-104">        }</span>
<span class="source-line-no">105</span><span id="line-105">    }</span>
<span class="source-line-no">106</span><span id="line-106"></span>
<span class="source-line-no">107</span><span id="line-107">    /**</span>
<span class="source-line-no">108</span><span id="line-108">     * Trains a sparse linear model.</span>
<span class="source-line-no">109</span><span id="line-109">     * @param examples The data set containing the examples.</span>
<span class="source-line-no">110</span><span id="line-110">     * @return A trained sparse linear model.</span>
<span class="source-line-no">111</span><span id="line-111">     */</span>
<span class="source-line-no">112</span><span id="line-112">    @Override</span>
<span class="source-line-no">113</span><span id="line-113">    public SparseLinearModel train(Dataset&lt;Regressor&gt; examples, Map&lt;String, Provenance&gt; runProvenance) {</span>
<span class="source-line-no">114</span><span id="line-114">        if (examples.getOutputInfo().getUnknownCount() &gt; 0) {</span>
<span class="source-line-no">115</span><span id="line-115">            throw new IllegalArgumentException("The supplied Dataset contained unknown Outputs, and this Trainer is supervised.");</span>
<span class="source-line-no">116</span><span id="line-116">        }</span>
<span class="source-line-no">117</span><span id="line-117"></span>
<span class="source-line-no">118</span><span id="line-118">        TrainerProvenance trainerProvenance;</span>
<span class="source-line-no">119</span><span id="line-119">        synchronized(this) {</span>
<span class="source-line-no">120</span><span id="line-120">            trainerProvenance = getProvenance();</span>
<span class="source-line-no">121</span><span id="line-121">            trainInvocationCounter++;</span>
<span class="source-line-no">122</span><span id="line-122">        }</span>
<span class="source-line-no">123</span><span id="line-123">        ImmutableOutputInfo&lt;Regressor&gt; outputInfo = examples.getOutputIDInfo();</span>
<span class="source-line-no">124</span><span id="line-124">        ImmutableFeatureMap featureIDMap = examples.getFeatureIDMap();</span>
<span class="source-line-no">125</span><span id="line-125">        Set&lt;Regressor&gt; domain = outputInfo.getDomain();</span>
<span class="source-line-no">126</span><span id="line-126">        int numOutputs = outputInfo.size();</span>
<span class="source-line-no">127</span><span id="line-127">        int numExamples = examples.size();</span>
<span class="source-line-no">128</span><span id="line-128">        int numFeatures = normalize ? featureIDMap.size() : featureIDMap.size() + 1; //include bias</span>
<span class="source-line-no">129</span><span id="line-129">        double[][] outputs = new double[numOutputs][numExamples];</span>
<span class="source-line-no">130</span><span id="line-130">        SparseVector[] inputs = new SparseVector[numExamples];</span>
<span class="source-line-no">131</span><span id="line-131">        int n = 0;</span>
<span class="source-line-no">132</span><span id="line-132">        for (Example&lt;Regressor&gt; e : examples) {</span>
<span class="source-line-no">133</span><span id="line-133">            inputs[n] = SparseVector.createSparseVector(e,featureIDMap,!normalize);</span>
<span class="source-line-no">134</span><span id="line-134">            double curWeight = Math.sqrt(e.getWeight());</span>
<span class="source-line-no">135</span><span id="line-135">            inputs[n].scaleInPlace(curWeight); //rescale features by example weight</span>
<span class="source-line-no">136</span><span id="line-136">            for (Regressor.DimensionTuple r : e.getOutput()) {</span>
<span class="source-line-no">137</span><span id="line-137">                int id = outputInfo.getID(r);</span>
<span class="source-line-no">138</span><span id="line-138">                outputs[id][n] = r.getValue() * curWeight; //rescale output by example weight</span>
<span class="source-line-no">139</span><span id="line-139">            }</span>
<span class="source-line-no">140</span><span id="line-140">            n++;</span>
<span class="source-line-no">141</span><span id="line-141">        }</span>
<span class="source-line-no">142</span><span id="line-142"></span>
<span class="source-line-no">143</span><span id="line-143">        // Extract featureMatrix from the sparse vectors</span>
<span class="source-line-no">144</span><span id="line-144">        RealMatrix featureMatrix = new Array2DRowRealMatrix(numExamples, numFeatures);</span>
<span class="source-line-no">145</span><span id="line-145">        double[] denseFeatures = new double[numFeatures];</span>
<span class="source-line-no">146</span><span id="line-146">        for (int i = 0; i &lt; inputs.length; i++) {</span>
<span class="source-line-no">147</span><span id="line-147">            Arrays.fill(denseFeatures,0.0);</span>
<span class="source-line-no">148</span><span id="line-148">            for (VectorTuple vec : inputs[i]) {</span>
<span class="source-line-no">149</span><span id="line-149">                denseFeatures[vec.index] = vec.value;</span>
<span class="source-line-no">150</span><span id="line-150">            }</span>
<span class="source-line-no">151</span><span id="line-151">            featureMatrix.setRow(i, denseFeatures);</span>
<span class="source-line-no">152</span><span id="line-152">        }</span>
<span class="source-line-no">153</span><span id="line-153"></span>
<span class="source-line-no">154</span><span id="line-154">        double[] featureMeans = new double[numFeatures];</span>
<span class="source-line-no">155</span><span id="line-155">        double[] featureVariances = new double[numFeatures];</span>
<span class="source-line-no">156</span><span id="line-156">        double[] outputMeans = new double[numOutputs];</span>
<span class="source-line-no">157</span><span id="line-157">        double[] outputVariances = new double[numOutputs];</span>
<span class="source-line-no">158</span><span id="line-158">        if (normalize) {</span>
<span class="source-line-no">159</span><span id="line-159">            for (int i = 0; i &lt; numFeatures; ++i) {</span>
<span class="source-line-no">160</span><span id="line-160">                double[] featV = featureMatrix.getColumn(i);</span>
<span class="source-line-no">161</span><span id="line-161">                featureMeans[i] = Util.mean(featV);</span>
<span class="source-line-no">162</span><span id="line-162"></span>
<span class="source-line-no">163</span><span id="line-163">                for (int j=0; j &lt; featV.length; ++j) {</span>
<span class="source-line-no">164</span><span id="line-164">                    featV[j] -= featureMeans[i];</span>
<span class="source-line-no">165</span><span id="line-165">                }</span>
<span class="source-line-no">166</span><span id="line-166"></span>
<span class="source-line-no">167</span><span id="line-167">                RealVector xp = new ArrayRealVector(featV);</span>
<span class="source-line-no">168</span><span id="line-168">                featureVariances[i] = xp.getNorm();</span>
<span class="source-line-no">169</span><span id="line-169">                featureMatrix.setColumnVector(i,xp.mapDivideToSelf(featureVariances[i]));</span>
<span class="source-line-no">170</span><span id="line-170">            }</span>
<span class="source-line-no">171</span><span id="line-171"></span>
<span class="source-line-no">172</span><span id="line-172">            for (int i = 0; i &lt; numOutputs; i++) {</span>
<span class="source-line-no">173</span><span id="line-173">                outputMeans[i] = Util.mean(outputs[i]);</span>
<span class="source-line-no">174</span><span id="line-174">                // Remove mean and aggregate variance</span>
<span class="source-line-no">175</span><span id="line-175">                double sum = 0.0;</span>
<span class="source-line-no">176</span><span id="line-176">                for (int j = 0; j &lt; numExamples; j++) {</span>
<span class="source-line-no">177</span><span id="line-177">                    outputs[i][j] -= outputMeans[i];</span>
<span class="source-line-no">178</span><span id="line-178">                    sum += outputs[i][j] * outputs[i][j];</span>
<span class="source-line-no">179</span><span id="line-179">                }</span>
<span class="source-line-no">180</span><span id="line-180">                outputVariances[i] = Math.sqrt(sum);</span>
<span class="source-line-no">181</span><span id="line-181">                // Remove variance</span>
<span class="source-line-no">182</span><span id="line-182">                for (int j = 0; j &lt; numExamples; j++) {</span>
<span class="source-line-no">183</span><span id="line-183">                    outputs[i][j] /= outputVariances[i];</span>
<span class="source-line-no">184</span><span id="line-184">                }</span>
<span class="source-line-no">185</span><span id="line-185">            }</span>
<span class="source-line-no">186</span><span id="line-186">        } else {</span>
<span class="source-line-no">187</span><span id="line-187">            Arrays.fill(featureMeans,0.0);</span>
<span class="source-line-no">188</span><span id="line-188">            Arrays.fill(featureVariances,1.0);</span>
<span class="source-line-no">189</span><span id="line-189">            Arrays.fill(outputMeans,0.0);</span>
<span class="source-line-no">190</span><span id="line-190">            Arrays.fill(outputVariances,1.0);</span>
<span class="source-line-no">191</span><span id="line-191">        }</span>
<span class="source-line-no">192</span><span id="line-192"></span>
<span class="source-line-no">193</span><span id="line-193">        // Construct the output matrix from the double[][] after scaling</span>
<span class="source-line-no">194</span><span id="line-194">        RealMatrix outputMatrix = new Array2DRowRealMatrix(outputs);</span>
<span class="source-line-no">195</span><span id="line-195"></span>
<span class="source-line-no">196</span><span id="line-196">        // Array example is useful to compute a submatrix</span>
<span class="source-line-no">197</span><span id="line-197">        int[] exampleRows = new int[numExamples];</span>
<span class="source-line-no">198</span><span id="line-198">        for (int i = 0; i &lt; numExamples; ++i) {</span>
<span class="source-line-no">199</span><span id="line-199">            exampleRows[i] = i;</span>
<span class="source-line-no">200</span><span id="line-200">        }</span>
<span class="source-line-no">201</span><span id="line-201"></span>
<span class="source-line-no">202</span><span id="line-202">        RealVector one = new ArrayRealVector(numExamples,1.0);</span>
<span class="source-line-no">203</span><span id="line-203"></span>
<span class="source-line-no">204</span><span id="line-204">        int numToSelect;</span>
<span class="source-line-no">205</span><span id="line-205">        if ((maxNumFeatures &lt; 1) || (maxNumFeatures &gt; featureIDMap.size())) {</span>
<span class="source-line-no">206</span><span id="line-206">            numToSelect = featureIDMap.size();</span>
<span class="source-line-no">207</span><span id="line-207">        } else {</span>
<span class="source-line-no">208</span><span id="line-208">            numToSelect = maxNumFeatures;</span>
<span class="source-line-no">209</span><span id="line-209">        }</span>
<span class="source-line-no">210</span><span id="line-210"></span>
<span class="source-line-no">211</span><span id="line-211">        String[] dimensionNames = new String[numOutputs];</span>
<span class="source-line-no">212</span><span id="line-212">        SparseVector[] modelWeights = new SparseVector[numOutputs];</span>
<span class="source-line-no">213</span><span id="line-213">        for (Regressor r : domain) {</span>
<span class="source-line-no">214</span><span id="line-214">            int id = outputInfo.getID(r);</span>
<span class="source-line-no">215</span><span id="line-215">            dimensionNames[id] = r.getNames()[0];</span>
<span class="source-line-no">216</span><span id="line-216">            SLMState state = new SLMState(featureMatrix,outputMatrix.getRowVector(id),featureIDMap,normalize);</span>
<span class="source-line-no">217</span><span id="line-217">            modelWeights[id] = trainSingleDimension(state,exampleRows,numToSelect,one);</span>
<span class="source-line-no">218</span><span id="line-218">        }</span>
<span class="source-line-no">219</span><span id="line-219"></span>
<span class="source-line-no">220</span><span id="line-220">        ModelProvenance provenance = new ModelProvenance(SparseLinearModel.class.getName(), OffsetDateTime.now(), examples.getProvenance(), trainerProvenance, runProvenance);</span>
<span class="source-line-no">221</span><span id="line-221">        return new SparseLinearModel("slm-model", dimensionNames, provenance, featureIDMap, outputInfo, modelWeights,</span>
<span class="source-line-no">222</span><span id="line-222">                DenseVector.createDenseVector(featureMeans), DenseVector.createDenseVector(featureVariances),</span>
<span class="source-line-no">223</span><span id="line-223">                outputMeans, outputVariances, !normalize);</span>
<span class="source-line-no">224</span><span id="line-224">    }</span>
<span class="source-line-no">225</span><span id="line-225"></span>
<span class="source-line-no">226</span><span id="line-226">    @Override</span>
<span class="source-line-no">227</span><span id="line-227">    public int getInvocationCount() {</span>
<span class="source-line-no">228</span><span id="line-228">        return trainInvocationCounter;</span>
<span class="source-line-no">229</span><span id="line-229">    }</span>
<span class="source-line-no">230</span><span id="line-230"></span>
<span class="source-line-no">231</span><span id="line-231">    @Override</span>
<span class="source-line-no">232</span><span id="line-232">    public TrainerProvenance getProvenance() {</span>
<span class="source-line-no">233</span><span id="line-233">        return new TrainerProvenanceImpl(this);</span>
<span class="source-line-no">234</span><span id="line-234">    }</span>
<span class="source-line-no">235</span><span id="line-235"></span>
<span class="source-line-no">236</span><span id="line-236">    @Override</span>
<span class="source-line-no">237</span><span id="line-237">    public String toString() {</span>
<span class="source-line-no">238</span><span id="line-238">        return "SFSTrainer(normalize="+normalize+",maxNumFeatures="+maxNumFeatures+")";</span>
<span class="source-line-no">239</span><span id="line-239">    }</span>
<span class="source-line-no">240</span><span id="line-240"></span>
<span class="source-line-no">241</span><span id="line-241">    /**</span>
<span class="source-line-no">242</span><span id="line-242">     * Trains a single dimension.</span>
<span class="source-line-no">243</span><span id="line-243">     * @param state The state object to use.</span>
<span class="source-line-no">244</span><span id="line-244">     * @param exampleRows An array with the row indices in.</span>
<span class="source-line-no">245</span><span id="line-245">     * @param numToSelect The number of features to select.</span>
<span class="source-line-no">246</span><span id="line-246">     * @param one A RealVector of ones.</span>
<span class="source-line-no">247</span><span id="line-247">     * @return The sparse vector representing the learned feature weights.</span>
<span class="source-line-no">248</span><span id="line-248">     */</span>
<span class="source-line-no">249</span><span id="line-249">    private SparseVector trainSingleDimension(SLMState state, int[] exampleRows, int numToSelect, RealVector one) {</span>
<span class="source-line-no">250</span><span id="line-250">        int iter = 0;</span>
<span class="source-line-no">251</span><span id="line-251">        while (state.active.size() &lt; numToSelect) {</span>
<span class="source-line-no">252</span><span id="line-252">            // Compute the residual</span>
<span class="source-line-no">253</span><span id="line-253">            state.r = state.y.subtract(state.X.operate(state.beta));</span>
<span class="source-line-no">254</span><span id="line-254"></span>
<span class="source-line-no">255</span><span id="line-255">            logger.info("At iteration " + iter + " Average residual " + state.r.dotProduct(one) / state.numExamples);</span>
<span class="source-line-no">256</span><span id="line-256">            iter++;</span>
<span class="source-line-no">257</span><span id="line-257">            // Compute the correlation</span>
<span class="source-line-no">258</span><span id="line-258">            state.corr = state.X.transpose().operate(state.r);</span>
<span class="source-line-no">259</span><span id="line-259"></span>
<span class="source-line-no">260</span><span id="line-260">            // Identify most correlated feature</span>
<span class="source-line-no">261</span><span id="line-261">            double max = -1;</span>
<span class="source-line-no">262</span><span id="line-262">            int feature = -1;</span>
<span class="source-line-no">263</span><span id="line-263">            for (int i = 0; i &lt; state.numFeatures; ++i) {</span>
<span class="source-line-no">264</span><span id="line-264">                if (!state.activeSet.contains(i)) {</span>
<span class="source-line-no">265</span><span id="line-265">                    double absCorr = Math.abs(state.corr.getEntry(i));</span>
<span class="source-line-no">266</span><span id="line-266"></span>
<span class="source-line-no">267</span><span id="line-267">                    if (absCorr &gt; max) {</span>
<span class="source-line-no">268</span><span id="line-268">                        max = absCorr;</span>
<span class="source-line-no">269</span><span id="line-269">                        feature = i;</span>
<span class="source-line-no">270</span><span id="line-270">                    }</span>
<span class="source-line-no">271</span><span id="line-271">                }</span>
<span class="source-line-no">272</span><span id="line-272">            }</span>
<span class="source-line-no">273</span><span id="line-273"></span>
<span class="source-line-no">274</span><span id="line-274">            state.C = max;</span>
<span class="source-line-no">275</span><span id="line-275"></span>
<span class="source-line-no">276</span><span id="line-276">            state.active.add(feature);</span>
<span class="source-line-no">277</span><span id="line-277">            state.activeSet.add(feature);</span>
<span class="source-line-no">278</span><span id="line-278"></span>
<span class="source-line-no">279</span><span id="line-279">            if (!state.normalize &amp;&amp; (feature == state.numFeatures-1)) {</span>
<span class="source-line-no">280</span><span id="line-280">                logger.info("Bias selected");</span>
<span class="source-line-no">281</span><span id="line-281">            } else {</span>
<span class="source-line-no">282</span><span id="line-282">                logger.info("Feature selected: " + state.featureIDMap.get(feature).getName() + " (pos=" + feature + ")");</span>
<span class="source-line-no">283</span><span id="line-283">            }</span>
<span class="source-line-no">284</span><span id="line-284"></span>
<span class="source-line-no">285</span><span id="line-285">            // Compute the active matrix</span>
<span class="source-line-no">286</span><span id="line-286">            int[] activeFeatures = Util.toPrimitiveInt(state.active);</span>
<span class="source-line-no">287</span><span id="line-287">            state.xpi = state.X.getSubMatrix(exampleRows, activeFeatures);</span>
<span class="source-line-no">288</span><span id="line-288"></span>
<span class="source-line-no">289</span><span id="line-289">            if (state.active.size() == (numToSelect - 1)) {</span>
<span class="source-line-no">290</span><span id="line-290">                state.last = true;</span>
<span class="source-line-no">291</span><span id="line-291">            }</span>
<span class="source-line-no">292</span><span id="line-292"></span>
<span class="source-line-no">293</span><span id="line-293">            RealVector betapi = newWeights(state);</span>
<span class="source-line-no">294</span><span id="line-294"></span>
<span class="source-line-no">295</span><span id="line-295">            if (betapi == null) {</span>
<span class="source-line-no">296</span><span id="line-296">                // Matrix was not invertible</span>
<span class="source-line-no">297</span><span id="line-297">                logger.log(Level.INFO, "Stopping at feature " + state.active.size() + " matrix was no longer invertible.");</span>
<span class="source-line-no">298</span><span id="line-298">                break;</span>
<span class="source-line-no">299</span><span id="line-299">            }</span>
<span class="source-line-no">300</span><span id="line-300"></span>
<span class="source-line-no">301</span><span id="line-301">            state.beta = betapi;</span>
<span class="source-line-no">302</span><span id="line-302">        }</span>
<span class="source-line-no">303</span><span id="line-303"></span>
<span class="source-line-no">304</span><span id="line-304">        Map&lt;Integer, Double&gt; parameters = new HashMap&lt;&gt;();</span>
<span class="source-line-no">305</span><span id="line-305"></span>
<span class="source-line-no">306</span><span id="line-306">        for (int i = 0; i &lt; state.numFeatures; ++i) {</span>
<span class="source-line-no">307</span><span id="line-307">            if (state.beta.getEntry(i) != 0) {</span>
<span class="source-line-no">308</span><span id="line-308">                parameters.put(i, state.beta.getEntry(i));</span>
<span class="source-line-no">309</span><span id="line-309">            }</span>
<span class="source-line-no">310</span><span id="line-310">        }</span>
<span class="source-line-no">311</span><span id="line-311"></span>
<span class="source-line-no">312</span><span id="line-312">        return SparseVector.createSparseVector(state.numFeatures, parameters);</span>
<span class="source-line-no">313</span><span id="line-313">    }</span>
<span class="source-line-no">314</span><span id="line-314"></span>
<span class="source-line-no">315</span><span id="line-315">    /**</span>
<span class="source-line-no">316</span><span id="line-316">     * Minimize ordinary least squares.</span>
<span class="source-line-no">317</span><span id="line-317">     *</span>
<span class="source-line-no">318</span><span id="line-318">     * Returns null if the matrix is not invertible.</span>
<span class="source-line-no">319</span><span id="line-319">     * @param M The matrix of features.</span>
<span class="source-line-no">320</span><span id="line-320">     * @param target The vector of target values.</span>
<span class="source-line-no">321</span><span id="line-321">     * @return The OLS solution for the supplied features.</span>
<span class="source-line-no">322</span><span id="line-322">     */</span>
<span class="source-line-no">323</span><span id="line-323">    static RealVector ordinaryLeastSquares(RealMatrix M, RealVector target) {</span>
<span class="source-line-no">324</span><span id="line-324">        RealMatrix inv;</span>
<span class="source-line-no">325</span><span id="line-325">        try {</span>
<span class="source-line-no">326</span><span id="line-326">            inv = new LUDecomposition(M.transpose().multiply(M)).getSolver().getInverse();</span>
<span class="source-line-no">327</span><span id="line-327">        } catch (SingularMatrixException s) {</span>
<span class="source-line-no">328</span><span id="line-328">            // Matrix is not invertible, there is nothing we can do</span>
<span class="source-line-no">329</span><span id="line-329">            // We will let the caller decide what to do</span>
<span class="source-line-no">330</span><span id="line-330">            return null;</span>
<span class="source-line-no">331</span><span id="line-331">        }</span>
<span class="source-line-no">332</span><span id="line-332"></span>
<span class="source-line-no">333</span><span id="line-333">        return inv.multiply(M.transpose()).operate(target);</span>
<span class="source-line-no">334</span><span id="line-334">    }</span>
<span class="source-line-no">335</span><span id="line-335"></span>
<span class="source-line-no">336</span><span id="line-336">    /**</span>
<span class="source-line-no">337</span><span id="line-337">     * Sums inverted matrix.</span>
<span class="source-line-no">338</span><span id="line-338">     * @param matrix The Matrix to operate on.</span>
<span class="source-line-no">339</span><span id="line-339">     * @return The sum of the inverted matrix.</span>
<span class="source-line-no">340</span><span id="line-340">     */</span>
<span class="source-line-no">341</span><span id="line-341">    static double sumInverted(RealMatrix matrix) {</span>
<span class="source-line-no">342</span><span id="line-342">        // Why are we not trying to catch the potential exception?</span>
<span class="source-line-no">343</span><span id="line-343">        // Because in the context of LARS, if we call this method, we know the matrix is invertible</span>
<span class="source-line-no">344</span><span id="line-344">        RealMatrix inv = new LUDecomposition(matrix.transpose().multiply(matrix)).getSolver().getInverse();</span>
<span class="source-line-no">345</span><span id="line-345"></span>
<span class="source-line-no">346</span><span id="line-346">        RealVector one = new ArrayRealVector(matrix.getColumnDimension(),1.0);</span>
<span class="source-line-no">347</span><span id="line-347"></span>
<span class="source-line-no">348</span><span id="line-348">        return one.dotProduct(inv.operate(one));</span>
<span class="source-line-no">349</span><span id="line-349">    }</span>
<span class="source-line-no">350</span><span id="line-350"></span>
<span class="source-line-no">351</span><span id="line-351">    /**</span>
<span class="source-line-no">352</span><span id="line-352">     * Inverts the matrix, takes the dot product and scales it by the supplied value.</span>
<span class="source-line-no">353</span><span id="line-353">     * @param M The matrix to invert.</span>
<span class="source-line-no">354</span><span id="line-354">     * @param AA The value to scale by.</span>
<span class="source-line-no">355</span><span id="line-355">     * @return The vector of feature values.</span>
<span class="source-line-no">356</span><span id="line-356">     */</span>
<span class="source-line-no">357</span><span id="line-357">    static RealVector getwa(RealMatrix M, double AA) {</span>
<span class="source-line-no">358</span><span id="line-358">        RealMatrix inv = new LUDecomposition(M.transpose().multiply(M)).getSolver().getInverse();</span>
<span class="source-line-no">359</span><span id="line-359">        RealVector one = new ArrayRealVector(M.getColumnDimension(),1.0);</span>
<span class="source-line-no">360</span><span id="line-360"></span>
<span class="source-line-no">361</span><span id="line-361">        return inv.operate(one).mapMultiply(AA);</span>
<span class="source-line-no">362</span><span id="line-362">    }</span>
<span class="source-line-no">363</span><span id="line-363"></span>
<span class="source-line-no">364</span><span id="line-364">    /**</span>
<span class="source-line-no">365</span><span id="line-365">     * Calculates (M . v) . D^T</span>
<span class="source-line-no">366</span><span id="line-366">     * Used in LARS.</span>
<span class="source-line-no">367</span><span id="line-367">     * @param D A matrix.</span>
<span class="source-line-no">368</span><span id="line-368">     * @param M A matrix.</span>
<span class="source-line-no">369</span><span id="line-369">     * @param v A vector.</span>
<span class="source-line-no">370</span><span id="line-370">     * @return (M . v) . D^T</span>
<span class="source-line-no">371</span><span id="line-371">     */</span>
<span class="source-line-no">372</span><span id="line-372">    static RealVector getA(RealMatrix D, RealMatrix M, RealVector v) {</span>
<span class="source-line-no">373</span><span id="line-373">        RealVector u = M.operate(v);</span>
<span class="source-line-no">374</span><span id="line-374">        return D.transpose().operate(u);</span>
<span class="source-line-no">375</span><span id="line-375">    }</span>
<span class="source-line-no">376</span><span id="line-376"></span>
<span class="source-line-no">377</span><span id="line-377">    static class SLMState {</span>
<span class="source-line-no">378</span><span id="line-378">        protected final int numExamples;</span>
<span class="source-line-no">379</span><span id="line-379">        protected final int numFeatures;</span>
<span class="source-line-no">380</span><span id="line-380">        protected final boolean normalize;</span>
<span class="source-line-no">381</span><span id="line-381">        protected final ImmutableFeatureMap featureIDMap;</span>
<span class="source-line-no">382</span><span id="line-382"></span>
<span class="source-line-no">383</span><span id="line-383">        protected final Set&lt;Integer&gt; activeSet;</span>
<span class="source-line-no">384</span><span id="line-384">        protected final List&lt;Integer&gt; active;</span>
<span class="source-line-no">385</span><span id="line-385"></span>
<span class="source-line-no">386</span><span id="line-386">        protected final RealMatrix X;</span>
<span class="source-line-no">387</span><span id="line-387">        protected final RealVector y;</span>
<span class="source-line-no">388</span><span id="line-388"></span>
<span class="source-line-no">389</span><span id="line-389">        protected RealMatrix xpi;</span>
<span class="source-line-no">390</span><span id="line-390">        protected RealVector r;</span>
<span class="source-line-no">391</span><span id="line-391">        protected RealVector beta;</span>
<span class="source-line-no">392</span><span id="line-392"></span>
<span class="source-line-no">393</span><span id="line-393">        protected double C;</span>
<span class="source-line-no">394</span><span id="line-394">        protected RealVector corr;</span>
<span class="source-line-no">395</span><span id="line-395"></span>
<span class="source-line-no">396</span><span id="line-396">        protected Boolean last = false;</span>
<span class="source-line-no">397</span><span id="line-397"></span>
<span class="source-line-no">398</span><span id="line-398">        public SLMState(RealMatrix features, RealVector outputs, ImmutableFeatureMap featureIDMap, boolean normalize) {</span>
<span class="source-line-no">399</span><span id="line-399">            this.numExamples = features.getRowDimension();</span>
<span class="source-line-no">400</span><span id="line-400">            this.numFeatures = features.getColumnDimension();</span>
<span class="source-line-no">401</span><span id="line-401">            this.featureIDMap = featureIDMap;</span>
<span class="source-line-no">402</span><span id="line-402">            this.normalize = normalize;</span>
<span class="source-line-no">403</span><span id="line-403">            this.active = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">404</span><span id="line-404">            this.activeSet = new HashSet&lt;&gt;();</span>
<span class="source-line-no">405</span><span id="line-405">            this.beta = new ArrayRealVector(numFeatures);</span>
<span class="source-line-no">406</span><span id="line-406">            this.X = features;</span>
<span class="source-line-no">407</span><span id="line-407">            this.y = outputs;</span>
<span class="source-line-no">408</span><span id="line-408">        }</span>
<span class="source-line-no">409</span><span id="line-409"></span>
<span class="source-line-no">410</span><span id="line-410">        /**</span>
<span class="source-line-no">411</span><span id="line-411">         * Unpacks the active set into a dense vector using the values in values</span>
<span class="source-line-no">412</span><span id="line-412">         * @param values The values.</span>
<span class="source-line-no">413</span><span id="line-413">         * @return A dense vector representing the values at the active set indices.</span>
<span class="source-line-no">414</span><span id="line-414">         */</span>
<span class="source-line-no">415</span><span id="line-415">        public RealVector unpack(RealVector values) {</span>
<span class="source-line-no">416</span><span id="line-416">            RealVector u = new ArrayRealVector(numFeatures);</span>
<span class="source-line-no">417</span><span id="line-417"></span>
<span class="source-line-no">418</span><span id="line-418">            for (int i = 0; i &lt; active.size(); ++i) {</span>
<span class="source-line-no">419</span><span id="line-419">                u.setEntry(active.get(i), values.getEntry(i));</span>
<span class="source-line-no">420</span><span id="line-420">            }</span>
<span class="source-line-no">421</span><span id="line-421"></span>
<span class="source-line-no">422</span><span id="line-422">            return u;</span>
<span class="source-line-no">423</span><span id="line-423">        }</span>
<span class="source-line-no">424</span><span id="line-424">    }</span>
<span class="source-line-no">425</span><span id="line-425">}</span>




























































</pre>
</div>
</main>
</body>
</html>
