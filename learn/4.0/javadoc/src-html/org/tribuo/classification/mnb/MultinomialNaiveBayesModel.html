<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (24) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.tribuo.classification.mnb, class: MultinomialNaiveBayesModel">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../resource-files/stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Copyright (c) 2015-2020, Oracle and/or its affiliates. All rights reserved.</span>
<span class="source-line-no">003</span><span id="line-3"> *</span>
<span class="source-line-no">004</span><span id="line-4"> * Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="source-line-no">005</span><span id="line-5"> * you may not use this file except in compliance with the License.</span>
<span class="source-line-no">006</span><span id="line-6"> * You may obtain a copy of the License at</span>
<span class="source-line-no">007</span><span id="line-7"> *</span>
<span class="source-line-no">008</span><span id="line-8"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">011</span><span id="line-11"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">012</span><span id="line-12"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express implied.</span>
<span class="source-line-no">013</span><span id="line-13"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">014</span><span id="line-14"> * limitations under the License.</span>
<span class="source-line-no">015</span><span id="line-15"> */</span>
<span class="source-line-no">016</span><span id="line-16"></span>
<span class="source-line-no">017</span><span id="line-17">package org.tribuo.classification.mnb;</span>
<span class="source-line-no">018</span><span id="line-18"></span>
<span class="source-line-no">019</span><span id="line-19">import com.oracle.labs.mlrg.olcut.util.Pair;</span>
<span class="source-line-no">020</span><span id="line-20">import org.tribuo.Example;</span>
<span class="source-line-no">021</span><span id="line-21">import org.tribuo.Excuse;</span>
<span class="source-line-no">022</span><span id="line-22">import org.tribuo.Feature;</span>
<span class="source-line-no">023</span><span id="line-23">import org.tribuo.ImmutableFeatureMap;</span>
<span class="source-line-no">024</span><span id="line-24">import org.tribuo.ImmutableOutputInfo;</span>
<span class="source-line-no">025</span><span id="line-25">import org.tribuo.Model;</span>
<span class="source-line-no">026</span><span id="line-26">import org.tribuo.Prediction;</span>
<span class="source-line-no">027</span><span id="line-27">import org.tribuo.classification.Label;</span>
<span class="source-line-no">028</span><span id="line-28">import org.tribuo.math.la.DenseSparseMatrix;</span>
<span class="source-line-no">029</span><span id="line-29">import org.tribuo.math.la.DenseVector;</span>
<span class="source-line-no">030</span><span id="line-30">import org.tribuo.math.la.SparseVector;</span>
<span class="source-line-no">031</span><span id="line-31">import org.tribuo.math.la.VectorTuple;</span>
<span class="source-line-no">032</span><span id="line-32">import org.tribuo.math.util.ExpNormalizer;</span>
<span class="source-line-no">033</span><span id="line-33">import org.tribuo.math.util.VectorNormalizer;</span>
<span class="source-line-no">034</span><span id="line-34">import org.tribuo.provenance.ModelProvenance;</span>
<span class="source-line-no">035</span><span id="line-35"></span>
<span class="source-line-no">036</span><span id="line-36">import java.util.ArrayList;</span>
<span class="source-line-no">037</span><span id="line-37">import java.util.Comparator;</span>
<span class="source-line-no">038</span><span id="line-38">import java.util.HashMap;</span>
<span class="source-line-no">039</span><span id="line-39">import java.util.LinkedHashMap;</span>
<span class="source-line-no">040</span><span id="line-40">import java.util.List;</span>
<span class="source-line-no">041</span><span id="line-41">import java.util.Map;</span>
<span class="source-line-no">042</span><span id="line-42">import java.util.Optional;</span>
<span class="source-line-no">043</span><span id="line-43"></span>
<span class="source-line-no">044</span><span id="line-44">/**</span>
<span class="source-line-no">045</span><span id="line-45"> * A {@link Model} for multinomial Naive Bayes with Laplace smoothing.</span>
<span class="source-line-no">046</span><span id="line-46"> * &lt;p&gt;</span>
<span class="source-line-no">047</span><span id="line-47"> * All feature values must be non-negative, otherwise it will throw IllegalArgumentException.</span>
<span class="source-line-no">048</span><span id="line-48"> * &lt;p&gt;</span>
<span class="source-line-no">049</span><span id="line-49"> * See:</span>
<span class="source-line-no">050</span><span id="line-50"> * &lt;pre&gt;</span>
<span class="source-line-no">051</span><span id="line-51"> * Wang S, Manning CD.</span>
<span class="source-line-no">052</span><span id="line-52"> * "Baselines and Bigrams: Simple, Good Sentiment and Topic Classification"</span>
<span class="source-line-no">053</span><span id="line-53"> * Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, 2012.</span>
<span class="source-line-no">054</span><span id="line-54"> * &lt;/pre&gt;</span>
<span class="source-line-no">055</span><span id="line-55"> */</span>
<span class="source-line-no">056</span><span id="line-56">public class MultinomialNaiveBayesModel extends Model&lt;Label&gt; {</span>
<span class="source-line-no">057</span><span id="line-57">    private static final long serialVersionUID = 1L;</span>
<span class="source-line-no">058</span><span id="line-58"></span>
<span class="source-line-no">059</span><span id="line-59">    private final DenseSparseMatrix labelWordProbs;</span>
<span class="source-line-no">060</span><span id="line-60">    private final double alpha;</span>
<span class="source-line-no">061</span><span id="line-61"></span>
<span class="source-line-no">062</span><span id="line-62">    private static final VectorNormalizer normalizer = new ExpNormalizer();</span>
<span class="source-line-no">063</span><span id="line-63"></span>
<span class="source-line-no">064</span><span id="line-64">    MultinomialNaiveBayesModel(String name, ModelProvenance description, ImmutableFeatureMap featureInfos, ImmutableOutputInfo&lt;Label&gt; labelInfos, DenseSparseMatrix labelWordProbs, double alpha) {</span>
<span class="source-line-no">065</span><span id="line-65">        super(name, description, featureInfos, labelInfos, true);</span>
<span class="source-line-no">066</span><span id="line-66">        this.labelWordProbs = labelWordProbs;</span>
<span class="source-line-no">067</span><span id="line-67">        this.alpha = alpha;</span>
<span class="source-line-no">068</span><span id="line-68">    }</span>
<span class="source-line-no">069</span><span id="line-69"></span>
<span class="source-line-no">070</span><span id="line-70">    @Override</span>
<span class="source-line-no">071</span><span id="line-71">    public Prediction&lt;Label&gt; predict(Example&lt;Label&gt; example) {</span>
<span class="source-line-no">072</span><span id="line-72">        SparseVector exVector = SparseVector.createSparseVector(example, featureIDMap, false);</span>
<span class="source-line-no">073</span><span id="line-73"></span>
<span class="source-line-no">074</span><span id="line-74">        if (exVector.minValue() &lt; 0.0) {</span>
<span class="source-line-no">075</span><span id="line-75">            throw new IllegalArgumentException("Example has negative feature values, example = " + example.toString());</span>
<span class="source-line-no">076</span><span id="line-76">        }</span>
<span class="source-line-no">077</span><span id="line-77">        if (exVector.numActiveElements() == 0) {</span>
<span class="source-line-no">078</span><span id="line-78">            throw new IllegalArgumentException("No features found in Example " + example.toString());</span>
<span class="source-line-no">079</span><span id="line-79">        }</span>
<span class="source-line-no">080</span><span id="line-80"></span>
<span class="source-line-no">081</span><span id="line-81">        /* Since we keep the label by feature matrix sparse, we need to manually</span>
<span class="source-line-no">082</span><span id="line-82">         * add the weights contributed by smoothing unobserved features. We need to</span>
<span class="source-line-no">083</span><span id="line-83">         * add in the portion of the inner product for the indices that are active</span>
<span class="source-line-no">084</span><span id="line-84">         * in the example but are not active in the labelWordProbs matrix (but are</span>
<span class="source-line-no">085</span><span id="line-85">         * still non-zero due to smoothing).</span>
<span class="source-line-no">086</span><span id="line-86">         */</span>
<span class="source-line-no">087</span><span id="line-87">        double[] alphaOffsets = new double[outputIDInfo.size()];</span>
<span class="source-line-no">088</span><span id="line-88">        int vocabSize = labelWordProbs.getDimension2Size();</span>
<span class="source-line-no">089</span><span id="line-89">        if (alpha &gt; 0.0) {</span>
<span class="source-line-no">090</span><span id="line-90">            for (int i = 0; i &lt; outputIDInfo.size(); i++) {</span>
<span class="source-line-no">091</span><span id="line-91">                double unobservedProb = Math.log(alpha / (labelWordProbs.getRow(i).oneNorm() + (vocabSize * alpha)));</span>
<span class="source-line-no">092</span><span id="line-92">                int[] mismatchedIndices = exVector.difference(labelWordProbs.getRow(i));</span>
<span class="source-line-no">093</span><span id="line-93">                double inExampleFactor = 0.0;</span>
<span class="source-line-no">094</span><span id="line-94">                for (int idx = 0; idx &lt; mismatchedIndices.length; idx++) {</span>
<span class="source-line-no">095</span><span id="line-95">                    // TODO - exVector.get is slow as it does a binary search into the vector.</span>
<span class="source-line-no">096</span><span id="line-96">                    inExampleFactor += exVector.get(mismatchedIndices[idx]) * unobservedProb;</span>
<span class="source-line-no">097</span><span id="line-97">                }</span>
<span class="source-line-no">098</span><span id="line-98">                alphaOffsets[i] = inExampleFactor;</span>
<span class="source-line-no">099</span><span id="line-99">            }</span>
<span class="source-line-no">100</span><span id="line-100">        }</span>
<span class="source-line-no">101</span><span id="line-101"></span>
<span class="source-line-no">102</span><span id="line-102">        DenseVector prediction = labelWordProbs.leftMultiply(exVector);</span>
<span class="source-line-no">103</span><span id="line-103">        prediction.intersectAndAddInPlace(DenseVector.createDenseVector(alphaOffsets));</span>
<span class="source-line-no">104</span><span id="line-104">        prediction.normalize(normalizer);</span>
<span class="source-line-no">105</span><span id="line-105">        Map&lt;String,Label&gt; distribution = new LinkedHashMap&lt;&gt;();</span>
<span class="source-line-no">106</span><span id="line-106">        Label maxLabel = null;</span>
<span class="source-line-no">107</span><span id="line-107">        double maxScore = Double.NEGATIVE_INFINITY;</span>
<span class="source-line-no">108</span><span id="line-108">        for(VectorTuple vt : prediction) {</span>
<span class="source-line-no">109</span><span id="line-109">            String name = outputIDInfo.getOutput(vt.index).getLabel();</span>
<span class="source-line-no">110</span><span id="line-110">            Label label = new Label(name, vt.value);</span>
<span class="source-line-no">111</span><span id="line-111">            if (vt.value &gt; maxScore) {</span>
<span class="source-line-no">112</span><span id="line-112">                maxScore = vt.value;</span>
<span class="source-line-no">113</span><span id="line-113">                maxLabel = label;</span>
<span class="source-line-no">114</span><span id="line-114">            }</span>
<span class="source-line-no">115</span><span id="line-115">            distribution.put(name,label);</span>
<span class="source-line-no">116</span><span id="line-116">        }</span>
<span class="source-line-no">117</span><span id="line-117">        Prediction&lt;Label&gt; p = new Prediction&lt;&gt;(maxLabel, distribution, exVector.numActiveElements(), example, true);</span>
<span class="source-line-no">118</span><span id="line-118">        return p;</span>
<span class="source-line-no">119</span><span id="line-119">    }</span>
<span class="source-line-no">120</span><span id="line-120"></span>
<span class="source-line-no">121</span><span id="line-121">    @Override</span>
<span class="source-line-no">122</span><span id="line-122">    public Map&lt;String, List&lt;Pair&lt;String, Double&gt;&gt;&gt; getTopFeatures(int n) {</span>
<span class="source-line-no">123</span><span id="line-123">        int maxFeatures = n &lt; 0 ? featureIDMap.size() : n;</span>
<span class="source-line-no">124</span><span id="line-124">        Map&lt;String, List&lt;Pair&lt;String, Double&gt;&gt;&gt; topFeatures = new HashMap&lt;&gt;();</span>
<span class="source-line-no">125</span><span id="line-125"></span>
<span class="source-line-no">126</span><span id="line-126">        for (Pair&lt;Integer,Label&gt; label : outputIDInfo) {</span>
<span class="source-line-no">127</span><span id="line-127">            List&lt;Pair&lt;String, Double&gt;&gt; features = new ArrayList&lt;&gt;(labelWordProbs.numActiveElements(label.getA()));</span>
<span class="source-line-no">128</span><span id="line-128">            for(VectorTuple vt : labelWordProbs.getRow(label.getA())) {</span>
<span class="source-line-no">129</span><span id="line-129">                features.add(new Pair&lt;&gt;(featureIDMap.get(vt.index).getName(), vt.value));</span>
<span class="source-line-no">130</span><span id="line-130">            }</span>
<span class="source-line-no">131</span><span id="line-131">            features.sort(Comparator.comparing(x -&gt; -x.getB()));</span>
<span class="source-line-no">132</span><span id="line-132">            if(maxFeatures &lt; featureIDMap.size()) {</span>
<span class="source-line-no">133</span><span id="line-133">                features = features.subList(0, maxFeatures);</span>
<span class="source-line-no">134</span><span id="line-134">            }</span>
<span class="source-line-no">135</span><span id="line-135">            topFeatures.put(label.getB().getLabel(), features);</span>
<span class="source-line-no">136</span><span id="line-136">        }</span>
<span class="source-line-no">137</span><span id="line-137">        return topFeatures;</span>
<span class="source-line-no">138</span><span id="line-138">    }</span>
<span class="source-line-no">139</span><span id="line-139"></span>
<span class="source-line-no">140</span><span id="line-140">    @Override</span>
<span class="source-line-no">141</span><span id="line-141">    public Optional&lt;Excuse&lt;Label&gt;&gt; getExcuse(Example&lt;Label&gt; example) {</span>
<span class="source-line-no">142</span><span id="line-142">        Map&lt;String, List&lt;Pair&lt;String, Double&gt;&gt;&gt; explanation = new HashMap&lt;&gt;();</span>
<span class="source-line-no">143</span><span id="line-143">        for (Pair&lt;Integer,Label&gt; label : outputIDInfo) {</span>
<span class="source-line-no">144</span><span id="line-144">            List&lt;Pair&lt;String, Double&gt;&gt; scores = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">145</span><span id="line-145">            for(Feature f : example) {</span>
<span class="source-line-no">146</span><span id="line-146">                int id = featureIDMap.getID(f.getName());</span>
<span class="source-line-no">147</span><span id="line-147">                if (id &gt; -1) {</span>
<span class="source-line-no">148</span><span id="line-148">                    scores.add(new Pair&lt;&gt;(f.getName(),labelWordProbs.getRow(label.getA()).get(id)));</span>
<span class="source-line-no">149</span><span id="line-149">                }</span>
<span class="source-line-no">150</span><span id="line-150">            }</span>
<span class="source-line-no">151</span><span id="line-151">            explanation.put(label.getB().getLabel(), scores);</span>
<span class="source-line-no">152</span><span id="line-152">        }</span>
<span class="source-line-no">153</span><span id="line-153">        return Optional.of(new Excuse&lt;&gt;(example, predict(example), explanation));</span>
<span class="source-line-no">154</span><span id="line-154">    }</span>
<span class="source-line-no">155</span><span id="line-155"></span>
<span class="source-line-no">156</span><span id="line-156">    @Override</span>
<span class="source-line-no">157</span><span id="line-157">    protected MultinomialNaiveBayesModel copy(String newName, ModelProvenance newProvenance) {</span>
<span class="source-line-no">158</span><span id="line-158">        return new MultinomialNaiveBayesModel(newName,newProvenance,featureIDMap,outputIDInfo,new DenseSparseMatrix(labelWordProbs),alpha);</span>
<span class="source-line-no">159</span><span id="line-159">    }</span>
<span class="source-line-no">160</span><span id="line-160">}</span>




























































</pre>
</div>
</main>
</body>
</html>
