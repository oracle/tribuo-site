---
title: "Regression"
og-title: "Regression Tutorial"
learn_nav: true
parent: Tutorials
nav_order: 304
is_notebook: true
notebook_url: https://github.com/oracle/tribuo/blob/main/tutorials/regression-tribuo-v4.ipynb
comment: ## DO NOT EDIT THIS FILE. IT IS COPIED FROM THE TRIBUO DOC. EDIT IT THERE. ##
---
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Regression-Tutorial">Regression Tutorial<a class="anchor-link" href="#Regression-Tutorial">&#182;</a></h1><p>This guide will show how to use Tribuo’s regression models to predict wine quality based on the <a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality">UCI Wine Quality</a> data set. We’ll experiment with several different regression trainers: two for training linear models (SGD and Adagrad) and one for training a tree ensemble via Tribuo’s wrapper on XGBoost (note: Tribuo's XGBoost support relies upon the Maven Central XGBoost jar which only contains binaries for x86_64 platforms). We’ll run these experiments by simply swapping in different implementations of Tribuo’s <code>Trainer</code> interface. We’ll also show how to evaluate regression models and describe some common evaluation metrics.</p>
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup">&#182;</a></h2><p>First you'll need to download the winequality dataset from UCI:</p>
<p><code>wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv</code></p>
<p>then we'll load in some jars and import a few packages.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">json</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
<span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">regression</span><span class="o">-</span><span class="n">sgd</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
<span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">regression</span><span class="o">-</span><span class="n">xgboost</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
<span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">regression</span><span class="o">-</span><span class="n">tree</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">java.nio.file.Path</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">java.nio.file.Paths</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">org.tribuo.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.data.csv.CSVLoader</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.datasource.ListDataSource</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.evaluation.TrainTestSplitter</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.math.optimisers.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.evaluation.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.sgd.RegressionObjective</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.sgd.linear.LinearSGDTrainer</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.sgd.objectives.SquaredLoss</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.rtree.CARTRegressionTrainer</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.xgboost.XGBoostRegressionTrainer</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.util.Util</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-data">Loading the data<a class="anchor-link" href="#Loading-the-data">&#182;</a></h2><p>In Tribuo, all the prediction types have an associated <code>OutputFactory</code> implementation, which can create the appropriate <code>Output</code> subclasses from an input. Here we're going to use <code>RegressionFactory</code> as we're performing regression. In Tribuo both single and multidimensional regression use the <code>Regressor</code> and <code>RegressionFactory</code> classes. We then pass the <code>regressionFactory</code> into the simple <code>CSVLoader</code> which reads all the columns into a <code>DataSource</code>. The winequality dataset uses <code>;</code> to separate the columns rather than the standard <code>,</code> so we change the default separator character. Note if your csv file isn't purely numeric or you wish to use a subset of the columns as features then you should use <code>CSVDataSource</code> which allows fine-grained control over the loading and featurisation process of your csv file. There's a columnar data tutorial which details the flexibility and power of our columnar processing infrastructure.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">regressionFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressionFactory</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">csvLoader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CSVLoader</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="sc">&#39;;&#39;</span><span class="p">,</span><span class="n">regressionFactory</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We don't have a pre-defined train test split, so we take 70% as the training data, and 30% as the test data. The data is randomised using the RNG seeded by the second value. Then we feed the split data sources into the training and testing datasets. These <code>MutableDataset</code>s manage all the metadata (e.g., feature &amp; output domains), and the mapping from feature names to feature id numbers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineSource</span> <span class="o">=</span> <span class="n">csvLoader</span><span class="p">.</span><span class="na">loadDataSource</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;winequality-red.csv&quot;</span><span class="p">),</span><span class="s">&quot;quality&quot;</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">splitter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TrainTestSplitter</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">wineSource</span><span class="p">,</span> <span class="mf">0.7f</span><span class="p">,</span> <span class="mi">0</span><span class="n">L</span><span class="p">);</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">trainData</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">splitter</span><span class="p">.</span><span class="na">getTrain</span><span class="p">());</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">evalData</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">splitter</span><span class="p">.</span><span class="na">getTest</span><span class="p">());</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Regression-in-Tribuo">Regression in Tribuo<a class="anchor-link" href="#Regression-in-Tribuo">&#182;</a></h2><p>Unlike most ML packages, regression in Tribuo is multidimensional by default. This means that each <code>Regressor</code> contains a vector of named values, which like the <code>Feature</code> objects are always kept sorted in lexicographic order. However unlike features, <code>Regressor</code> objects are dense, they always include all the dimensions, even if some are zero. In practice for an output type this isn't a strong restriction as if you're working in a multidimensional space then all dimensions will usually be present, and there are many fewer output dimensions than there are features.</p>
<p>Given this difference from other libraries, you might as why Tribuo does it this way? It's because it makes operating on probability distributions using regression algorithms significantly simpler. We do this in Tribuo's implementation of <a href="https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf">LIME</a> for classification model explanations, and it will make future implementations of gradient boosting and similar algorithms much easier.</p>
<p>How does this affect users of Tribuo's regression package? Well, each <code>Regressor</code> is an <code>Iterable&lt;DimensionTuple&gt;</code>, and a <code>DimensionTuple</code> represents the name of a dimension, along with it's regressed value and a variance if present (unknown variances are set to <code>Double.NaN</code>). If you don't name the dimensions during data loading then they are automatically named <code>DIM-0</code>, ... <code>DIM-N</code> where <code>N</code> is one less than the number of dimensions. This means in the common case of single dimensional regression you'll want to access the first element of the various state accessors, or by asking the <code>Regressor</code> for <code>DIM-0</code>, or index <code>0</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="n">Regressor</span> <span class="n">r</span> <span class="o">=</span> <span class="n">trainData</span><span class="p">.</span><span class="na">getExample</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="na">getOutput</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Num dimensions = &quot;</span> <span class="o">+</span> <span class="n">r</span><span class="p">.</span><span class="na">size</span><span class="p">());</span>

<span class="n">String</span><span class="o">[]</span> <span class="n">dimNames</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="na">getNames</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Dimension name: &quot;</span> <span class="o">+</span> <span class="n">dimNames</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">);</span>

<span class="kt">double</span><span class="o">[]</span> <span class="n">regressedValues</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="na">getValues</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Dimension value: &quot;</span> <span class="o">+</span> <span class="n">regressedValues</span><span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">);</span>

<span class="c1">// getDimension(String) returns an Optional&lt;DimensionTuple&gt;</span>
<span class="n">Regressor</span><span class="p">.</span><span class="na">DimensionTuple</span> <span class="n">tuple</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="na">getDimension</span><span class="p">(</span><span class="s">&quot;DIM-0&quot;</span><span class="p">).</span><span class="na">get</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Tuple = [&quot;</span> <span class="o">+</span> <span class="n">tuple</span> <span class="o">+</span><span class="s">&quot;]&quot;</span><span class="p">);</span>

<span class="c1">// getDimension(int) throws IndexOutOfBoundsException if you give it a negative index</span>
<span class="c1">// or one greater than or equal to r.size()</span>
<span class="n">Regressor</span><span class="p">.</span><span class="na">DimensionTuple</span> <span class="n">tupleI</span> <span class="o">=</span> <span class="n">r</span><span class="p">.</span><span class="na">getDimension</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Regressor[0] = &quot;</span> <span class="o">+</span> <span class="n">tupleI</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Num dimensions = 1
Dimension name: DIM-0
Dimension value: 6.0
Tuple = [DIM-0=6.0]
Regressor[0] = DIM-0=6.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The prediction objects produced by Tribuo's regression models contain a single <code>Regressor</code> with a value for each dimension output the model knows about. As each <code>Regressor</code> represents a full vector there is no need for a collection of them to represent the full output space, unlike <code>Label</code> in multi-class classification.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-the-models">Training the models<a class="anchor-link" href="#Training-the-models">&#182;</a></h2><p>We're going to define a quick training function which accepts a trainer and a training dataset. It times the training and also prints the performance metrics. Evaluating on the training data is useful for debugging: if the model performs poorly in the training data, then we know something is wrong with either our model or our data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">public</span> <span class="n">Model</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="nf">train</span><span class="p">(</span><span class="n">String</span> <span class="n">name</span><span class="p">,</span> <span class="n">Trainer</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">trainData</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Train the model</span>
    <span class="kd">var</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
    <span class="n">Model</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">trainData</span><span class="p">);</span>
    <span class="kd">var</span> <span class="n">endTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
    <span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Training &quot;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s">&quot; took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">startTime</span><span class="p">,</span><span class="n">endTime</span><span class="p">));</span>
    <span class="c1">// Evaluate the model on the training data</span>
    <span class="c1">// This is a useful debugging tool to check the model actually learned something</span>
    <span class="n">RegressionEvaluator</span> <span class="n">eval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressionEvaluator</span><span class="p">();</span>
    <span class="kd">var</span> <span class="n">evaluation</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">trainData</span><span class="p">);</span>
    <span class="c1">// We create a dimension here to aid pulling out the appropriate statistics.</span>
    <span class="c1">// You can also produce the String directly by calling &quot;evaluation.toString()&quot;</span>
    <span class="kd">var</span> <span class="n">dimension</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Regressor</span><span class="p">(</span><span class="s">&quot;DIM-0&quot;</span><span class="p">,</span><span class="n">Double</span><span class="p">.</span><span class="na">NaN</span><span class="p">);</span>
    <span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">printf</span><span class="p">(</span><span class="s">&quot;Evaluation (train):%n  RMSE %f%n  MAE %f%n  R^2 %f%n&quot;</span><span class="p">,</span>
            <span class="n">evaluation</span><span class="p">.</span><span class="na">rmse</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span> <span class="n">evaluation</span><span class="p">.</span><span class="na">mae</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span> <span class="n">evaluation</span><span class="p">.</span><span class="na">r2</span><span class="p">(</span><span class="n">dimension</span><span class="p">));</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we're going to define an equivalent testing function which accepts a model and a test dataset, printing the performance to std out.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">public</span> <span class="kt">void</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">Model</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">model</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span> <span class="n">testData</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Evaluate the model on the test data</span>
    <span class="n">RegressionEvaluator</span> <span class="n">eval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressionEvaluator</span><span class="p">();</span>
    <span class="kd">var</span> <span class="n">evaluation</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">testData</span><span class="p">);</span>
    <span class="c1">// We create a dimension here to aid pulling out the appropriate statistics.</span>
    <span class="c1">// You can also produce the String directly by calling &quot;evaluation.toString()&quot;</span>
    <span class="kd">var</span> <span class="n">dimension</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Regressor</span><span class="p">(</span><span class="s">&quot;DIM-0&quot;</span><span class="p">,</span><span class="n">Double</span><span class="p">.</span><span class="na">NaN</span><span class="p">);</span>
    <span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">printf</span><span class="p">(</span><span class="s">&quot;Evaluation (test):%n  RMSE %f%n  MAE %f%n  R^2 %f%n&quot;</span><span class="p">,</span>
            <span class="n">evaluation</span><span class="p">.</span><span class="na">rmse</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span> <span class="n">evaluation</span><span class="p">.</span><span class="na">mae</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span> <span class="n">evaluation</span><span class="p">.</span><span class="na">r2</span><span class="p">(</span><span class="n">dimension</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll define the four trainers we're going to compare.</p>
<ul>
<li>A linear regression trained using linear decay SGD.</li>
<li>A linear regression trained using SGD and AdaGrad.</li>
<li>A regression tree using the CART algorithm with a maximum depth of 6.</li>
<li>An XGBoost trainer using 50 rounds of boosting.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">lrsgd</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LinearSGDTrainer</span><span class="p">(</span>
    <span class="k">new</span> <span class="n">SquaredLoss</span><span class="p">(),</span> <span class="c1">// loss function</span>
    <span class="n">SGD</span><span class="p">.</span><span class="na">getLinearDecaySGD</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="c1">// gradient descent algorithm</span>
    <span class="mi">10</span><span class="p">,</span>                <span class="c1">// number of training epochs</span>
    <span class="n">trainData</span><span class="p">.</span><span class="na">size</span><span class="p">()</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span><span class="c1">// logging interval</span>
    <span class="mi">1</span><span class="p">,</span>                 <span class="c1">// minibatch size</span>
    <span class="mi">1L</span>                 <span class="c1">// RNG seed</span>
<span class="p">);</span>
<span class="kd">var</span> <span class="n">lrada</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LinearSGDTrainer</span><span class="p">(</span>
    <span class="k">new</span> <span class="n">SquaredLoss</span><span class="p">(),</span>
    <span class="k">new</span> <span class="n">AdaGrad</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span>
    <span class="mi">10</span><span class="p">,</span>
    <span class="n">trainData</span><span class="p">.</span><span class="na">size</span><span class="p">()</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">,</span>
    <span class="mi">1L</span> 
<span class="p">);</span>
<span class="kd">var</span> <span class="n">cart</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CARTRegressionTrainer</span><span class="p">(</span><span class="mi">6</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">xgb</span> <span class="o">=</span> <span class="k">new</span> <span class="n">XGBoostRegressionTrainer</span><span class="p">(</span><span class="mi">50</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll train the linear regression with SGD:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">lrsgdModel</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="s">&quot;Linear Regression (SGD)&quot;</span><span class="p">,</span><span class="n">lrsgd</span><span class="p">,</span><span class="n">trainData</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training Linear Regression (SGD) took (00:00:00:070)
Evaluation (train):
  RMSE 0.979522
  MAE 0.741870
  R^2 -0.471611
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluating-the-models">Evaluating the models<a class="anchor-link" href="#Evaluating-the-models">&#182;</a></h2><p>Using our evaluation function this is pretty straightforward.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">lrsgdModel</span><span class="p">,</span><span class="n">evalData</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Evaluation (test):
  RMSE 0.967450
  MAE 0.720619
  R^2 -0.439255
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Those numbers seem poor, but what do these evaluation metrics mean?</p>
<h3 id="RMSE">RMSE<a class="anchor-link" href="#RMSE">&#182;</a></h3><p>The root-mean-square error (RMSE) summarizes the magnitude of errors between our regression model's predictions and the values we observe in our data. Basically, RMSE is the standard deviation of model prediction errors on a given dataset.</p>
$$RMSE = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 }$$<p>Lower is better: a perfect model for the wine data would have RMSE=0. The RMSE is sensitive to how large an error was, and is thus sensitive to outliers. This also means that RMSE can be used to compare different models on the same dataset but not across different datasets, as a "good" RMSE value on one dataset might be larger than a "good" RMSE value on a different dataset. See <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">Wikipedia</a> for more info on RMSE.</p>
<h3 id="MAE">MAE<a class="anchor-link" href="#MAE">&#182;</a></h3><p>The mean absolute error (MAE) is another summary of model error. Unlike RMSE, each error in MAE contributes proportional to its absolute value.</p>
$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$<h3 id="R%5E2">R^2<a class="anchor-link" href="#R%5E2">&#182;</a></h3><p>The R-squared metric (also called the "coefficient of determination") summarizes how much of the variation in observed outcomes can be explained by our model.</p>
<p>Let $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$, i.e., the mean deviation of observed data points from the observed mean. R^2 is given by:</p>
$$R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$$<p>A value of R^2=1 means that the model accounts for all of the variation in a set of observations -- in other words, it fits a dataset perfectly. Note that R^2 can turn negative when the sum-of-squared model errors (numerator) is greater than the sum-of-squared differences between observed data points and the observed mean (denominator). In other words, when R^2 is negative, the model fits the data <em>worse</em> than simply using the observed mean to predict values.</p>
<p>See <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">Wikipedia</a> and the <a href="https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit">Minitab blog</a> for more detailed discussion of R^2.</p>
<h2 id="Improving-over-standard-SGD-with-AdaGrad">Improving over standard SGD with AdaGrad<a class="anchor-link" href="#Improving-over-standard-SGD-with-AdaGrad">&#182;</a></h2><p>It's not surprising the SGD results are bad: in linear decay SGD, the step size used for parameter updates changes over time (training iterations) but is uniform across all model parameters. This means that we use the same step size for a noisy/irrelevant feature as we would for an informative feature. There are many more sophisticated approaches to stochastic gradient descent.</p>
<p>One of these is <a href="http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf">AdaGrad</a>, which modifies the "global" learning rate for each parameter $p$ using the sum-of-squares of past gradients w.r.t. $p$, up to time $t$.</p>
<blockquote><p>... the secret sauce of AdaGrad is not on necessarily accelerating gradient descent with a better step size selection, but making gradient descent more stable to not-so-good (\eta) choices.
Anastasios Kyrillidis, <a href="http://akyrillidis.github.io/notes/AdaGrad">Note on AdaGrad</a></p>
</blockquote>
<p>Let's try training for the same number of epochs using <code>AdaGrad</code> instead of <code>LinearDecaySGD</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">lradaModel</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="s">&quot;Linear Regression (AdaGrad)&quot;</span><span class="p">,</span><span class="n">lrada</span><span class="p">,</span><span class="n">trainData</span><span class="p">);</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">lradaModel</span><span class="p">,</span><span class="n">evalData</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training Linear Regression (AdaGrad) took (00:00:00:041)
Evaluation (train):
  RMSE 0.735311
  MAE 0.575096
  R^2 0.170709
Evaluation (test):
  RMSE 0.737994
  MAE 0.585709
  R^2 0.162497
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using a more robust optimizer got us a better fit in the same number of epochs. However, both the train and test R^2 scores are still substantially less than 1 and, as before, the train and test RMSE scores are very similar.</p>
<p>See <a href="http://akyrillidis.github.io/notes/AdaGrad">here</a> and <a href="http://ruder.io/optimizing-gradient-descent/index.html#adagrad">here</a> for more on AdaGrad. Also, there are many other implementations of various well-known optimizers in Tribuo, including <a href="https://tribuo.org/learn/4.1/javadoc/org/tribuo/math/optimisers/Adam.html">Adam</a> and <a href="https://tribuo.org/learn/4.1/javadoc/org/tribuo/math/optimisers/RMSProp.html">RMSProp</a>. See the <a href="https://tribuo.org/learn/4.1/javadoc/org/tribuo/math/optimisers/package-summary.html">math.optimisers</a> package.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point, we showed that we can improve our model by using a more robust optimizer; however, we're still using a linear model. If there are informative, non-linear relationships among wine quality features, then our current model won't be able to take advantage of them. We'll finish this tutorial by showing how to use a couple of popular non-linear models, CART and <a href="https://xgboost.ai">XGBoost</a>.</p>
<h2 id="Trees-and-ensembles">Trees and ensembles<a class="anchor-link" href="#Trees-and-ensembles">&#182;</a></h2><p>Next we'll train the CART tree:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">cartModel</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="s">&quot;CART&quot;</span><span class="p">,</span><span class="n">cart</span><span class="p">,</span><span class="n">trainData</span><span class="p">);</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">cartModel</span><span class="p">,</span><span class="n">evalData</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training CART took (00:00:00:071)
Evaluation (train):
  RMSE 0.544516
  MAE 0.405062
  R^2 0.545236
Evaluation (test):
  RMSE 0.658722
  MAE 0.494395
  R^2 0.332754
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we'll train the XGBoost ensemble:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">xgbModel</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="s">&quot;XGBoost&quot;</span><span class="p">,</span><span class="n">xgb</span><span class="p">,</span><span class="n">trainData</span><span class="p">);</span>
<span class="n">evaluate</span><span class="p">(</span><span class="n">xgbModel</span><span class="p">,</span><span class="n">evalData</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training XGBoost took (00:00:00:263)
Evaluation (train):
  RMSE 0.143871
  MAE 0.097167
  R^2 0.968252
Evaluation (test):
  RMSE 0.599478
  MAE 0.426673
  R^2 0.447378
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using gradient boosting via XGBoost improved results by a lot. Not only are the train &amp; test fits better, but the train and test RMSE have started to diverge a little, indicating that the XGBoost model isn't underfitting like the two linear models were. XGBoost won't always be the best model for your data, but it's often a great baseline model to try when facing a new problem or dataset.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><p>In this tutorial, we showed how to experiment with several different regression trainers (linear decay SGD, AdaGrad, CART, XGBoost). It was easy to experiment with different trainers and models by simply swapping in different implementations of the Tribuo <code>Trainer</code> interface. We also showed how to evaluate regression models and described some common evaluation metrics.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

