---
title: "Multi-Label Classification"
og-title: "Multi-Label Classification Tutorial"
learn_nav: true
parent: Tutorials
nav_order: 306
is_notebook: true
notebook_url: https://github.com/oracle/tribuo/blob/main/tutorials/multi-label-tribuo-v4.ipynb
comment: ## DO NOT EDIT THIS FILE. IT IS COPIED FROM THE TRIBUO DOC. EDIT IT THERE. ##
---
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Multi-Label-Classification-Tutorial">Multi-Label Classification Tutorial<a class="anchor-link" href="#Multi-Label-Classification-Tutorial">&#182;</a></h1><p>This tutorial shows how to use Tribuo's MultiLabel package to perform <a href="https://en.wikipedia.org/wiki/Multi-label_classification">multi-label classification</a> tasks. Multi-label classification is the task of assigning a <em>set</em> of labels to a given example from a specific label domain, as opposed to multi-class classification which is assigning a <em>single</em> label to a given example.</p>
<p>Tribuo provides linear model and factorization machine algorithms for native multi-label prediction, along with ensemble methods that either predict each label independently or as part of a <a href="http://www.cs.waikato.ac.nz/~ml/publications/2009/chains.pdf">classifier chain</a>, using any of Tribuo's classification algorithms as the base learners. Both the linear models, factorization machines and the <code>IndependentMultiLabelTrainer</code> use the <em>Binary Relevance</em> approach to multi-label prediction, where each label is predicted independently. The <code>ClassifierChainTrainer</code> and <code>CCEnsembleTrainer</code> use classifier chains which incorporate label structure into the prediction. In this tutorial we'll cover loading in multi-label data, performing predictions using several binary relevance based classifiers along with some classifier chains, and finally we'll evaluate the multi-label models using Tribuo's multi-label evaluation package.</p>
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup">&#182;</a></h2><p>First you'll need a copy of the multi-label yeast dataset (we'll download these from the <a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">LibSVM</a> dataset repo):</p>

<pre><code>wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel/yeast_train.svm.bz2
wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multilabel/yeast_test.svm.bz2</code></pre>
<p>Then you should extract it using your preferred method. On macOS and Linux you can use <code>bunzip2</code>, and on Windows there are several packages which can extract bz2 files (e.g., <a href="https://www.7-zip.org/">7-zip</a>).</p>
<p>This dataset has 14 labels which represent different functional groups and the task is to predict the functional groups a gene belongs in based on micro-array expression measurements. Fortunately we don't need a PhD in Genetics to use this dataset as a benchmark, though obviously domain knowledge would be critical if we wanted to actually deploy any model based on this data.</p>
<p>Now we'll load in the necessary jars and import some packages from the JDK and Tribuo.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">multilabel</span><span class="o">-</span><span class="n">sgd</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
<span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">classification</span><span class="o">-</span><span class="n">experiments</span><span class="o">-</span><span class="mf">4.2.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">java.nio.file.Paths</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">org.tribuo.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.classification.Label</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.classification.dtree.CARTClassificationTrainer</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.classification.dtree.impurity.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.datasource.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.math.optimisers.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.baseline.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.ensemble.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.evaluation.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.sgd.linear.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.multilabel.sgd.objectives.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.util.Util</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-data">Loading the data<a class="anchor-link" href="#Loading-the-data">&#182;</a></h2><p>There are two main forms for multi-label data in columnar representations. Either the dataset stores the labels in a single column using some delimiter (e.g., "first_label,third_label"), resulting in a sparse representation of the labels, or each label is stored in it's own column with a flag representing if that label is present (e.g., "TRUE" or "1"), resulting in a dense representation of the labels. Tribuo can load both formats, though currently the <code>MultiLabelFactory</code> only supports comma separated labels when parsing inputs directly from a <code>String</code>. When processing multi-label values through a <code>RowProcessor</code> then the factory receives a <code>List&lt;String&gt;</code> and processes each separate label appropriately.</p>
<p>The yeast dataset we downloaded is stored in libsvm format which uses a sparse representation of the labels, so we'll use Tribuo's <code>LibSVMDataSource</code> to load it in, and process the outputs through a <code>MultiLabelFactory</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">factory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MultiLabelFactory</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">trainSource</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LibSVMDataSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;.&quot;</span><span class="p">,</span><span class="s">&quot;yeast_train.svm&quot;</span><span class="p">),</span><span class="n">factory</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">testSource</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LibSVMDataSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;.&quot;</span><span class="p">,</span><span class="s">&quot;yeast_test.svm&quot;</span><span class="p">),</span><span class="n">factory</span><span class="p">,</span><span class="n">trainSource</span><span class="p">.</span><span class="na">isZeroIndexed</span><span class="p">(),</span><span class="n">trainSource</span><span class="p">.</span><span class="na">getMaxFeatureID</span><span class="p">());</span>
<span class="kd">var</span> <span class="n">train</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">trainSource</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">test</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">testSource</span><span class="p">);</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;Training data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">train</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">train</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">train</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;Testing data size = %d, number of features = %d, number of classes = %d&quot;</span><span class="p">,</span><span class="n">test</span><span class="p">.</span><span class="na">size</span><span class="p">(),</span><span class="n">test</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span><span class="n">test</span><span class="p">.</span><span class="na">getOutputInfo</span><span class="p">().</span><span class="na">size</span><span class="p">()));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training data size = 1500, number of features = 103, number of classes = 14
Testing data size = 917, number of features = 103, number of classes = 14
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Tribuo we represent a multi-label task using the <code>org.tribuo.multilabel.MultiLabel</code> output, which internally uses a set of <code>org.tribuo.classification.Label</code> objects to store the individual labels. This means that unlike most Tribuo prediction type packages, <code>tribuo-multilabel-core</code> depends on another output core package <code>tribuo-classification-core</code>. <code>MultiLabel</code> is a sparse representation of the labels, only the <code>Label</code>s which are active are stored in the <code>MultiLabel</code> object.</p>
<p>We can inspect the first output from the training dataset to see this:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;First output = &quot;</span> <span class="o">+</span> <span class="n">train</span><span class="p">.</span><span class="na">getExample</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="na">getOutput</span><span class="p">());</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Second output = &quot;</span> <span class="o">+</span> <span class="n">train</span><span class="p">.</span><span class="na">getExample</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="na">getOutput</span><span class="p">());</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>First output = (LabelSet={2,3})
Second output = (LabelSet={11,12,6,7})
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This first example is tagged with labels 2 &amp; 3, and the second one is tagged with 6, 7, 11 and 12. Unfortunately the LibSVM format we loaded in uses numbers rather than names for the labels, but if there are more descriptive names present when the data is loaded in then those would be used as the label names.</p>
<h2 id="The-task-of-multi-label-prediction">The task of multi-label prediction<a class="anchor-link" href="#The-task-of-multi-label-prediction">&#182;</a></h2><p>Multi-label problems can be approached in several different ways. A common approach is to treat each label as an independent function of the input features, this leads to the <em>binary relevance</em> approach where each label is independent from each other, and multi-label classification can be thought of as a set of standard binary classification problems. This approach scales well, but if there is underlying structure in the label space (e.g., the label "human" implies the label "animal", but the label "animal" does not imply "human", so they are not independent), then this approach ignores useful information from the training data and may underperform more complicated approaches. Another popular way to convert a multi-label problem into a standard classification problem is via a <em>label powerset</em>, where each unique combination of the individual labels is treated as a single label in a large multi-class classification problem. While this allows the learning algorithm to fully capture any interactions between the labels, the label powerset is exponential in the number of labels, which rapidly makes this approach intractable as the number of labels increases though it can be useful in small label spaces. Tribuo currently focuses on binary relevance and other approaches which don't require exponential computation, though we're happy to discuss incorporating label powerset methods if people have need for them.</p>
<h2 id="Training-Binary-Relevance-models">Training Binary Relevance models<a class="anchor-link" href="#Training-Binary-Relevance-models">&#182;</a></h2><p>Now we'll train a few different binary relevance models (i.e., independent predictions of each label). First we'll use Tribuo's multi-label <code>LinearSGDModel</code> which natively makes multi-label predictions, then we'll wrap a binary classification decision tree into a multi-label predictor using <code>IndependentMultiLabelTrainer</code> and <code>IndependentMultiLabelModel</code>. Note: Tribuo has three classes called <code>LinearSGDModel</code>, one each for <code>Label</code>, <code>MultiLabel</code>, and <code>Regressor</code>, so the <code>LinearSGDModel</code> used in this tutorial is <code>org.tribuo.multilabel.sgd.linear.LinearSGDModel</code>, and the one used in the <em>multi-class</em> classification tutorials is <code>org.tribuo.classification.sgd.linear.LinearSGDModel</code>.</p>
<p>Tribuo's multi-label SGD package supports two different objective functions, Binary Cross-Entropy and Hinge loss. The BCE loss produces probabilitistic outputs thresholded at 0.5, whereas the hinge loss produces scores thresholded at 0. As Tribuo usually produces scores for each possible label, these thresholds are used to determine when a particular label is present in the <code>MultiLabel</code> object representing the predicted label set. As you may have seen in other tutorials, Tribuo uses stochastic gradient descent to fit it's linear models, so we'll define a gradient optimizer along with the loss function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">linTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LinearSGDTrainer</span><span class="p">(</span><span class="k">new</span> <span class="n">BinaryCrossEntropy</span><span class="p">(),</span><span class="k">new</span> <span class="n">AdaGrad</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">),</span><span class="mi">5</span><span class="p">,</span><span class="mi">1000</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">Trainer</span><span class="p">.</span><span class="na">DEFAULT_SEED</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We train the model the same way we train the rest of Tribuo's models.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">linStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">linModel</span> <span class="o">=</span> <span class="n">linTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">train</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">linEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Linear model training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">linStartTime</span><span class="p">,</span><span class="n">linEndTime</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Linear model training took (00:00:00:245)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tribuo doesn't have a native implementation of a multi-label decision tree, but it does have a multi-class decision tree, which we can convert into a multi-label predictor using <code>IndependentMultiLabelTrainer</code>. Now let's train a model using a decision tree to predict each label independently. First we define the binary classification trainer, then we'll use <code>IndependentMultiLabelTrainer</code> to wrap that <code>Trainer&lt;Label&gt;</code> and convert it into a <code>Trainer&lt;MultiLabel&gt;</code>, before training as usual.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="n">Trainer</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span> <span class="n">treeTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CARTClassificationTrainer</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.0f</span><span class="p">,</span><span class="mf">1.0f</span><span class="p">,</span><span class="kc">false</span><span class="p">,</span><span class="k">new</span> <span class="n">Entropy</span><span class="p">(),</span><span class="mi">1L</span><span class="p">);</span>
<span class="n">Trainer</span><span class="o">&lt;</span><span class="n">MultiLabel</span><span class="o">&gt;</span> <span class="n">dtTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IndependentMultiLabelTrainer</span><span class="p">(</span><span class="n">treeTrainer</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">dtStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">dtModel</span> <span class="o">=</span> <span class="n">dtTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">train</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">dtEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Tree model training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">dtStartTime</span><span class="p">,</span><span class="n">dtEndTime</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Tree model training took (00:00:03:499)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We've now got two different models, so let's measure their performance.</p>
<h2 id="Evaluating-multi-class-problems">Evaluating multi-class problems<a class="anchor-link" href="#Evaluating-multi-class-problems">&#182;</a></h2><p>Multi-label problems have many evaluation options available, as many standard classification evaluation measures like accuracy, precision, recall and F1 can be applied at the label level, and there are also many set level metric such as the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard Index</a> which can be used to compare the predicted label set against the ground truth one. In Tribuo we have access to most of the metrics available for multi-class classification problems, and v4.2 began adding set level metrics as well. If there are useful metrics that aren't implemented in Tribuo raise an issue on Tribuo's <a href="https://github.com/oracle/tribuo">Github page</a>.</p>
<p>If you want to use the predicted scores for each of the labels separately (e.g., to analyse the model's performance) then as usual the <code>Map&lt;String,MultiLabel&gt;</code> available from <code>Prediction.getOutputScores()</code> has the full distribution. This map behaves slightly counter-intuitively, as each value is a <code>MultiLabel</code> object containing a single <code>Label</code>, and the key is the output of <code>Label.toString()</code>. This allows the labels to be inspected individually, but it is a little uncomfortable if you're used to working with a multi-label specific API. However it maintains conformity across all of Tribuo's different prediction APIs, both for predictions and evaluations, which makes it easier to incorporate lots of ML models into a larger system.</p>
<p>We use the same evaluation paradigm as other Tribuo prediction tasks, first we construct an <code>Evaluator</code> and then feed it a model and some test data to produce an <code>Evaluation</code> which contains the appropriate performance metrics.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">eval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MultiLabelEvaluator</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll look at the linear model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">linTStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">linEval</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">linModel</span><span class="p">,</span><span class="n">test</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">linTEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Linear model evaluation took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">linTStartTime</span><span class="p">,</span><span class="n">linTEndTime</span><span class="p">));</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">linEval</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Linear model evaluation took (00:00:00:073)
Class                           n          tp          fn          fp      recall        prec          f1
(LabelSet={12})               683         677           6         230       0.991       0.746       0.852
(LabelSet={13})                13           0          13           0       0.000       0.000       0.000
(LabelSet={0})                286         131         155          45       0.458       0.744       0.567
(LabelSet={1})                393         162         231         130       0.412       0.555       0.473
(LabelSet={2})                385         231         154          95       0.600       0.709       0.650
(LabelSet={3})                330         169         161          79       0.512       0.681       0.585
(LabelSet={4})                281         106         175          35       0.377       0.752       0.502
(LabelSet={5})                219          26         193          14       0.119       0.650       0.201
(LabelSet={6})                167           0         167           0       0.000       0.000       0.000
(LabelSet={7})                191           0         191           0       0.000       0.000       0.000
(LabelSet={8})                 80           0          80           0       0.000       0.000       0.000
(LabelSet={9})                 92           0          92           0       0.000       0.000       0.000
(LabelSet={10})                91           0          91           0       0.000       0.000       0.000
(LabelSet={11})               688         684           4         226       0.994       0.752       0.856
Total                       3,899       2,186       1,713         854
Accuracy                                                                    0.561
Micro Average                                                               0.561       0.719       0.630
Macro Average                                                               0.319       0.399       0.335
Balanced Error Rate                                                         0.681
Jaccard Score                                                               0.497
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, the decision tree:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">dtTStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">dtEval</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">dtModel</span><span class="p">,</span><span class="n">test</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">dtTEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Tree model evaluation took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">dtTStartTime</span><span class="p">,</span><span class="n">dtTEndTime</span><span class="p">));</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">dtEval</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Tree model evaluation took (00:00:00:085)
Class                           n          tp          fn          fp      recall        prec          f1
(LabelSet={12})               683         607          76         201       0.889       0.751       0.814
(LabelSet={13})                13           0          13           2       0.000       0.000       0.000
(LabelSet={0})                286         111         175          98       0.388       0.531       0.448
(LabelSet={1})                393         187         206         181       0.476       0.508       0.491
(LabelSet={2})                385         251         134         193       0.652       0.565       0.606
(LabelSet={3})                330         131         199          67       0.397       0.662       0.496
(LabelSet={4})                281          92         189          41       0.327       0.692       0.444
(LabelSet={5})                219          88         131         189       0.402       0.318       0.355
(LabelSet={6})                167          30         137          41       0.180       0.423       0.252
(LabelSet={7})                191          29         162          46       0.152       0.387       0.218
(LabelSet={8})                 80           1          79          12       0.013       0.077       0.022
(LabelSet={9})                 92          14          78          35       0.152       0.286       0.199
(LabelSet={10})                91          20          71          83       0.220       0.194       0.206
(LabelSet={11})               688         633          55         202       0.920       0.758       0.831
Total                       3,899       2,194       1,705       1,391
Accuracy                                                                    0.563
Micro Average                                                               0.563       0.612       0.586
Macro Average                                                               0.369       0.439       0.384
Balanced Error Rate                                                         0.631
Jaccard Score                                                               0.439
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the native multi-label linear model outperformed the wrapped decision tree in terms of Jaccard Score, though the picture is more mixed in the other metrics, and the linear model is ignoring some of the labels.</p>
<p>Unfortunately some of the metrics we might like to examine for regular multi-class classification aren't as easy to use in the multi-label case. For example, a multi-class confusion matrix has no direct analogue in the multi-label case, as there could be an arbitrary number of labels predicted for each output, meaning there is no notion of a label being mispredicted as another label. This means a multi-label confusion matrix is best presented as a series of binary confusion matrices, one per label. This tends to take up a lot of space, so we'll skip inspecting them in this tutorial, though they are accessible on the <code>MultiLabelEvaluation</code> object.</p>
<p>Now let's look at a more complicated multi-label classification approach, using <em>Classifier Chains</em>.</p>
<h2 id="Training-Classifier-Chains">Training Classifier Chains<a class="anchor-link" href="#Training-Classifier-Chains">&#182;</a></h2><p>A <a href="http://www.cs.waikato.ac.nz/~ml/publications/2009/chains.pdf">classifier chain</a> is similar to a binary relevance model, except there is a sequential order to the predictions (forming a chain), and each member of the chain receives extra features in the form of the predictions of earlier members of the chain. This means that if the chain is correctly ordered according to the causal structure of the labels (which is tricky to do) then it can start with the most independent label first, and then predict each label in sequence so it can use the earlier predictions to improve predictions for each subsequent label (e.g., we could predict if the example is an "animal" first, and then when we come to predict if it's a "human" we know that humans are animals making the prediction task easier).</p>
<p>In practice we don't usually know the correct ordering of the labels as the causal structure is unknown, and if we supply the incorrect structure then we can reduce performance back to the level of the binary relevance models. Fortunately in Machine Learning we have a trick we can use when we need to deal with uncertain data, which is to randomize it many times, and take an average. So we could take many different classifier chains each with an random label order, and then each chain votes on the labels that should be predicted. This improves statistical performance over a single chain with a random order, and over a single chain with a poorly chosen order, though it's unlikely to beat a single classifier chain with the correct label ordering (if such an ordering exists). Unfortunately the classifier chain ensemble is more expensive computationally than the single chain, which is already relatively expensive compared to a single classifier like <code>LinearSGDModel</code>, but the chains can be straightforwardly parallelized (and we'll add support for this to a future version of Tribuo).</p>
<p>We're going to use a single classifier chain with a random order, and then an ensemble of 20 classifier chains each using random orders to see how they perform.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">ccTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ClassifierChainTrainer</span><span class="p">(</span><span class="n">treeTrainer</span><span class="p">,</span><span class="mi">1L</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">ccEnsembleTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CCEnsembleTrainer</span><span class="p">(</span><span class="n">treeTrainer</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">1L</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll train and evaluate the single chain:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="c1">// train the model</span>
<span class="kd">var</span> <span class="n">ccStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">ccModel</span> <span class="o">=</span> <span class="n">ccTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">train</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">ccEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Classifier Chain model training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">ccStartTime</span><span class="p">,</span><span class="n">ccEndTime</span><span class="p">));</span>

<span class="c1">// evaluate the model</span>
<span class="kd">var</span> <span class="n">ccTStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">ccEval</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">ccModel</span><span class="p">,</span><span class="n">test</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">ccTEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Classifier Chain model evaluation took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">ccTStartTime</span><span class="p">,</span><span class="n">ccTEndTime</span><span class="p">));</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">ccEval</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Classifier Chain model training took (00:00:03:195)
Classifier Chain model evaluation took (00:00:00:146)
Class                           n          tp          fn          fp      recall        prec          f1
(LabelSet={12})               683         616          67         203       0.902       0.752       0.820
(LabelSet={13})                13           0          13           2       0.000       0.000       0.000
(LabelSet={0})                286         159         127         172       0.556       0.480       0.515
(LabelSet={1})                393         215         178         213       0.547       0.502       0.524
(LabelSet={2})                385         251         134         193       0.652       0.565       0.606
(LabelSet={3})                330         199         131         151       0.603       0.569       0.585
(LabelSet={4})                281         112         169         124       0.399       0.475       0.433
(LabelSet={5})                219          74         145         116       0.338       0.389       0.362
(LabelSet={6})                167          39         128          48       0.234       0.448       0.307
(LabelSet={7})                191          40         151          51       0.209       0.440       0.284
(LabelSet={8})                 80           0          80          14       0.000       0.000       0.000
(LabelSet={9})                 92           7          85          30       0.076       0.189       0.109
(LabelSet={10})                91           8          83          32       0.088       0.200       0.122
(LabelSet={11})               688         615          73         192       0.894       0.762       0.823
Total                       3,899       2,335       1,564       1,541
Accuracy                                                                    0.599
Micro Average                                                               0.599       0.602       0.601
Macro Average                                                               0.393       0.412       0.392
Balanced Error Rate                                                         0.607
Jaccard Score                                                               0.473
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the classifier chain improved over the binary relevance model when using trees as the base learner, and took roughly the same amount of time to train and evaluate. It's still not quite up to the linear model, but let's try the chain ensemble and see how it does.</p>
<p>Now we'll train and evaluate the ensemble:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="c1">// train the model</span>
<span class="kd">var</span> <span class="n">ccEnsembleStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">ccEnsembleModel</span> <span class="o">=</span> <span class="n">ccEnsembleTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">train</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">ccEnsembleEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Classifier Chain Ensemble model training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">ccEnsembleStartTime</span><span class="p">,</span><span class="n">ccEnsembleEndTime</span><span class="p">));</span>

<span class="c1">// evaluate the model</span>
<span class="kd">var</span> <span class="n">ccETStartTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">ccEnsembleEval</span> <span class="o">=</span> <span class="n">eval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">ccEnsembleModel</span><span class="p">,</span><span class="n">test</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">ccETEndTime</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Classifier Chain Ensemble model evaluation took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">ccETStartTime</span><span class="p">,</span><span class="n">ccETEndTime</span><span class="p">));</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">ccEnsembleEval</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>
Classifier Chain Ensemble model training took (00:01:04:418)
Classifier Chain Ensemble model evaluation took (00:00:02:474)
Class                           n          tp          fn          fp      recall        prec          f1
(LabelSet={12})               683         629          54         216       0.921       0.744       0.823
(LabelSet={13})                13           0          13           1       0.000       0.000       0.000
(LabelSet={0})                286         112         174          64       0.392       0.636       0.485
(LabelSet={1})                393         170         223         140       0.433       0.548       0.484
(LabelSet={2})                385         254         131         146       0.660       0.635       0.647
(LabelSet={3})                330         194         136         111       0.588       0.636       0.611
(LabelSet={4})                281         112         169          45       0.399       0.713       0.511
(LabelSet={5})                219          49         170          40       0.224       0.551       0.318
(LabelSet={6})                167          14         153           6       0.084       0.700       0.150
(LabelSet={7})                191          14         177          19       0.073       0.424       0.125
(LabelSet={8})                 80           0          80           0       0.000       0.000       0.000
(LabelSet={9})                 92           0          92           4       0.000       0.000       0.000
(LabelSet={10})                91           2          89           2       0.022       0.500       0.042
(LabelSet={11})               688         640          48         205       0.930       0.757       0.835
Total                       3,899       2,190       1,709         999
Accuracy                                                                    0.562
Micro Average                                                               0.562       0.687       0.618
Macro Average                                                               0.337       0.489       0.359
Balanced Error Rate                                                         0.663
Jaccard Score                                                               0.485
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected the classifier chain ensemble outperformed the binary relevance model and the single classifier chain when using trees as the base learner, at the cost of the greatest runtime. It did this by significantly decreasing the number of false positives, at the cost of a small increase in false negatives. We didn't quite beat the performance of the linear model in terms of Jaccard score, but in general classifier chains are a powerful multi-label approach, and we could always use the linear model as a base learner (and if you do, then you do improve the Jaccard score above 0.497). We leave the implementation of that as an exercise for the reader.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><p>We looked at Tribuo's multi-label classification package, trying out several different models using different approaches to the multi-label problem, namely binary relevance models and classifier chains. We're interested in expanding Tribuo's support for multi-label problems, so if there are algorithms or metrics Tribuo is missing head over to our <a href="https://github.com/oracle/tribuo">Github page</a> and contributions are always welcome.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

