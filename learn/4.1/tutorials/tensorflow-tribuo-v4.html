---
title: "Deep Learning with TensorFlow"
og-title: "Deep Learning with TensorFlow Tutorial"
learn_nav: true
parent: Tutorials
nav_order: 309
is_notebook: true
notebook_url: https://github.com/oracle/tribuo/blob/main/tutorials/tensorflow-tribuo-v4.ipynb
comment: ## DO NOT EDIT THIS FILE. IT IS COPIED FROM THE TRIBUO DOC. EDIT IT THERE. ##
---
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="TensorFlow-tutorial">TensorFlow tutorial<a class="anchor-link" href="#TensorFlow-tutorial">&#182;</a></h1><p>In this tutorial we'll show how to build deep learning models in Tribuo, using Tribuo's <a href="https://tensorflow.org">TensorFlow</a> interface. Tribuo uses <a href="https://github.com/tensorflow/java">TensorFlow-Java</a> which is build by the TensorFlow <a href="https://github.com/tensorflow/community/blob/master/sigs/jvm/CHARTER.md">SIG-JVM group</a>. Tribuo's development team are active participants in SIG-JVM, and we're trying to make TensorFlow work well for everyone on the Java platform, in addition to making it work well inside Tribuo.</p>
<p>Note that Tribuo's TensorFlow interface is not covered by the same stability guarantee as the rest of Tribuo. SIG-JVM has not released a 1.0 version of the TensorFlow Java API, and the API is currently in flux. When TensorFlow Java has API stability we'll be able to stabilize Tribuo's TensorFlow interface to provide the same guarantees as the rest of Tribuo.</p>
<p>We're going to train MLPs (Multi-Layer Perceptrons) for classification and regression, along with a CNN (Convolutional Neural Network) for classifying MNIST digits. We'll discuss loading in externally trained TensorFlow models and serving them alongside Tribuo's natively trained models. Finally we'll see how to export TensorFlow models trained in Tribuo into TensorFlow's SavedModelBundle format for interop with TensorFlow Serving and the rest of the TensorFlow ecosystem.</p>
<p>Unfortunately TensorFlow-Java has some non-determinism in it's gradient calculations which we're working on fixing in the TensorFlow-Java project, so repeated runs of this notebook will not produce identical answers, which unfortunately breaks some of Tribuo's provenance and reproducibility guarantees. When this is fixed upstream we'll apply any necessary fixes in Tribuo.</p>
<h2 id="Setup">Setup<a class="anchor-link" href="#Setup">&#182;</a></h2><p>You'll need to get a copy of the MNIST dataset in the original IDX format. You may have this from the configuration tutorial, in which case you can skip this step.</p>
<p>First the training data:</p>
<p><code>wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz</code></p>
<p>Then the test data:</p>
<p><code>wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz</code></p>
<p>Tribuo's IDX loader natively reads gzipped files so you don't need to unzip them.</p>
<p>We'll also need to download the winequality dataset from UCI. Again, if you've followed the regression tutorial you might already have this, so you can skip this step.</p>
<p><code>wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv</code></p>
<p>Next we'll load the Tribuo TensorFlow jar and import the packages we'll need for the rest of the tutorial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="o">%</span><span class="n">jars</span> <span class="p">.</span><span class="o">/</span><span class="n">tribuo</span><span class="o">-</span><span class="n">tensorflow</span><span class="o">-</span><span class="mf">4.1.0</span><span class="o">-</span><span class="n">jar</span><span class="o">-</span><span class="n">with</span><span class="o">-</span><span class="n">dependencies</span><span class="p">.</span><span class="na">jar</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">java.nio.file.Path</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">java.nio.file.Paths</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">org.tribuo.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.data.csv.CSVLoader</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.datasource.IDXDataSource</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.evaluation.TrainTestSplitter</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.classification.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.classification.evaluation.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.interop.tensorflow.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.interop.tensorflow.example.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.regression.evaluation.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tribuo.util.Util</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kn">import</span> <span class="nn">org.tensorflow.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tensorflow.framework.initializers.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tensorflow.ndarray.Shape</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tensorflow.op.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tensorflow.op.core.*</span><span class="p">;</span>
<span class="kn">import</span> <span class="nn">org.tensorflow.types.*</span><span class="p">;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-data">Loading the data<a class="anchor-link" href="#Loading-the-data">&#182;</a></h2><p>This is the same as the configuration and regression tutorials respectively, first we instantiate a <code>DataSource</code> for the particular dataset, then feed the data sources into datasets. We'll need to split the wine quality dataset into train &amp; test as it doesn't have a predefined train/test split.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="c1">// First we load winequality</span>
<span class="kd">var</span> <span class="n">regressionFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressionFactory</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">regEval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressionEvaluator</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">csvLoader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CSVLoader</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="sc">&#39;;&#39;</span><span class="p">,</span><span class="n">regressionFactory</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineSource</span> <span class="o">=</span> <span class="n">csvLoader</span><span class="p">.</span><span class="na">loadDataSource</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;winequality-red.csv&quot;</span><span class="p">),</span><span class="s">&quot;quality&quot;</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineSplitter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TrainTestSplitter</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">wineSource</span><span class="p">,</span> <span class="mf">0.7f</span><span class="p">,</span> <span class="mi">0</span><span class="n">L</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineTrain</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">wineSplitter</span><span class="p">.</span><span class="na">getTrain</span><span class="p">());</span>
<span class="kd">var</span> <span class="n">wineTest</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">wineSplitter</span><span class="p">.</span><span class="na">getTest</span><span class="p">());</span>

<span class="c1">// Now we load MNIST</span>
<span class="kd">var</span> <span class="n">labelFactory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LabelFactory</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">labelEval</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LabelEvaluator</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">mnistTrainSource</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IDXDataSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;train-images-idx3-ubyte.gz&quot;</span><span class="p">),</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;train-labels-idx1-ubyte.gz&quot;</span><span class="p">),</span><span class="n">labelFactory</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">mnistTestSource</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IDXDataSource</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;t10k-images-idx3-ubyte.gz&quot;</span><span class="p">),</span><span class="n">Paths</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="s">&quot;t10k-labels-idx1-ubyte.gz&quot;</span><span class="p">),</span><span class="n">labelFactory</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">mnistTrain</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">mnistTrainSource</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">mnistTest</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MutableDataset</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">mnistTestSource</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-a-TensorFlow-graph">Defining a TensorFlow graph<a class="anchor-link" href="#Defining-a-TensorFlow-graph">&#182;</a></h2><p>Tribuo's TensorFlow API operates on TensorFlow graphs. You can construct those using TensorFlow's Java API, load in ones already generated by another TensorFlow API, or use one of Tribuo's example graph generators. We're going to define a simple MLP for the wine quality regression task in the notebook, but we'll use Tribuo's example graph generators for classifying MNIST (to make this tutorial a little shorter).</p>
<p>TensorFlow Java is working on a higher level layer wise API (similar to <a href="https://www.tensorflow.org/api_docs/python/tf/keras">Keras</a>), but at the moment we have to define the graph using the low level ops. Once the layer API is available in TensorFlow Java, we'll add entry points so that those APIs can be used with Tribuo, making the next section of this tutorial a lot shorter. For the moment it'll be rather long, but hopefully it's not too hard to follow.</p>
<p>Tribuo's TensorFlow trainer will add the appropriate output node, loss function and gradient optimizer, so what you need to supply is the graph which emits the output (before any softmax, sigmoid or other output function), the name of the output op, the names of the input ops and the name of the graph initialization op.</p>
<h2 id="Building-a-regression-model-using-an-MLP">Building a regression model using an MLP<a class="anchor-link" href="#Building-a-regression-model-using-an-MLP">&#182;</a></h2><p>To solve this regression task we're going to build a 3 layer neural network, where each layer is a "dense" or "MLP" layer. We'll use a sigmoid as the activation function, but any supported one in TensorFlow will work. We'll need to know the number of input features and the number of output dimensions (i.e., the number of labels or regression dimensions), which is a little unfortunate as nothing else in Tribuo requires it, but it's required to build the structure.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineGraph</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Graph</span><span class="p">();</span>
<span class="c1">// This object is used to write operations into the graph</span>
<span class="kd">var</span> <span class="n">wineOps</span> <span class="o">=</span> <span class="n">Ops</span><span class="p">.</span><span class="na">create</span><span class="p">(</span><span class="n">wineGraph</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineInputName</span> <span class="o">=</span> <span class="s">&quot;WINE_INPUT&quot;</span><span class="p">;</span>
<span class="kt">long</span> <span class="n">wineNumFeatures</span> <span class="o">=</span> <span class="n">wineTrain</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">wineInitializer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Glorot</span><span class="o">&lt;</span><span class="n">TFloat32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">wineOps</span><span class="p">,</span> 
                                   <span class="c1">// Initializer distribution</span>
                                   <span class="n">VarianceScaling</span><span class="p">.</span><span class="na">Distribution</span><span class="p">.</span><span class="na">TRUNCATED_NORMAL</span><span class="p">,</span>
                                   <span class="c1">// Initializer seed</span>
                                   <span class="n">Trainer</span><span class="p">.</span><span class="na">DEFAULT_SEED</span>
                                   <span class="p">);</span>

<span class="c1">// The input placeholder that we&#39;ll feed the features into</span>
<span class="kd">var</span> <span class="n">wineInput</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">withName</span><span class="p">(</span><span class="n">wineInputName</span><span class="p">).</span><span class="na">placeholder</span><span class="p">(</span><span class="n">TFloat32</span><span class="p">.</span><span class="na">class</span><span class="p">,</span>
                <span class="n">Placeholder</span><span class="p">.</span><span class="na">shape</span><span class="p">(</span><span class="n">Shape</span><span class="p">.</span><span class="na">of</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">wineNumFeatures</span><span class="p">)));</span>
                
<span class="c1">// Fully connected layer (numFeatures -&gt; 30)</span>
<span class="kd">var</span> <span class="n">fc1Weights</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineInitializer</span><span class="p">.</span><span class="na">call</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="n">wineNumFeatures</span><span class="p">,</span> <span class="mi">30L</span><span class="p">),</span>
                                                   <span class="n">TFloat32</span><span class="p">.</span><span class="na">class</span><span class="p">));</span>
<span class="kd">var</span> <span class="n">fc1Biases</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">fill</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">constant</span><span class="p">(</span><span class="mf">0.1f</span><span class="p">)));</span>
<span class="kd">var</span> <span class="n">sigmoid1</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">math</span><span class="p">.</span><span class="na">sigmoid</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">math</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">linalg</span><span class="p">.</span><span class="na">matMul</span><span class="p">(</span><span class="n">wineInput</span><span class="p">,</span> <span class="n">fc1Weights</span><span class="p">),</span>
                                             <span class="n">fc1Biases</span><span class="p">));</span>

<span class="c1">// Fully connected layer (30 -&gt; 20)</span>
<span class="kd">var</span> <span class="n">fc2Weights</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineInitializer</span><span class="p">.</span><span class="na">call</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="mi">30L</span><span class="p">,</span> <span class="mi">20L</span><span class="p">),</span> 
                                                       <span class="n">TFloat32</span><span class="p">.</span><span class="na">class</span><span class="p">));</span>
<span class="kd">var</span> <span class="n">fc2Biases</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">fill</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">constant</span><span class="p">(</span><span class="mf">0.1f</span><span class="p">)));</span>
<span class="kd">var</span> <span class="n">sigmoid2</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">math</span><span class="p">.</span><span class="na">sigmoid</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">math</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">linalg</span><span class="p">.</span><span class="na">matMul</span><span class="p">(</span><span class="n">sigmoid1</span><span class="p">,</span> <span class="n">fc2Weights</span><span class="p">),</span> 
                                             <span class="n">fc2Biases</span><span class="p">));</span>

<span class="c1">// Output layer (20 -&gt; 1)</span>
<span class="kd">var</span> <span class="n">outputWeights</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineInitializer</span><span class="p">.</span><span class="na">call</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="mi">20L</span><span class="p">,</span> <span class="mi">1L</span><span class="p">),</span> 
                                                          <span class="n">TFloat32</span><span class="p">.</span><span class="na">class</span><span class="p">));</span>
<span class="kd">var</span> <span class="n">outputBiases</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">variable</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">fill</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">array</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">constant</span><span class="p">(</span><span class="mf">0.1f</span><span class="p">)));</span>
<span class="kd">var</span> <span class="n">outputOp</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">math</span><span class="p">.</span><span class="na">add</span><span class="p">(</span><span class="n">wineOps</span><span class="p">.</span><span class="na">linalg</span><span class="p">.</span><span class="na">matMul</span><span class="p">(</span><span class="n">sigmoid2</span><span class="p">,</span> <span class="n">outputWeights</span><span class="p">),</span> <span class="n">outputBiases</span><span class="p">);</span>

<span class="c1">// Build the Graph initialization operation</span>
<span class="kd">var</span> <span class="n">init</span> <span class="o">=</span> <span class="n">wineOps</span><span class="p">.</span><span class="na">init</span><span class="p">();</span>

<span class="c1">// Get the operation names to pass into the trainer</span>
<span class="kd">var</span> <span class="n">wineOutputName</span> <span class="o">=</span> <span class="n">outputOp</span><span class="p">.</span><span class="na">op</span><span class="p">().</span><span class="na">name</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">wineInitName</span> <span class="o">=</span> <span class="n">init</span><span class="p">.</span><span class="na">op</span><span class="p">().</span><span class="na">name</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can query the operation names by asking the various objects for their <code>name()</code>, which Tribuo will use to supply the appropriate inputs and outputs to the graph during training and inference.</p>
<p>Now we have the graph, input name, output name and init name, stored in <code>wineGraph</code>, <code>wineInputName</code>, <code>wineOutputName</code> and <code>wineInitName</code> respectively. Next we'll define the gradient optimization algorithm and it's hyperparameters. These are separate from Tribuo's built in gradient optimizers as they are part of the TensorFlow native library, but it turns out that most of the same algorithms are available. We're going to use <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad">AdaGrad</a>, set it's learning rate to <code>0.1f</code> and the initial accumulator value to <code>0.01f</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">gradAlgorithm</span> <span class="o">=</span> <span class="n">GradientOptimiser</span><span class="p">.</span><span class="na">ADAGRAD</span><span class="p">;</span>
<span class="kd">var</span> <span class="n">gradParams</span> <span class="o">=</span> <span class="n">Map</span><span class="p">.</span><span class="na">of</span><span class="p">(</span><span class="s">&quot;learningRate&quot;</span><span class="p">,</span><span class="mf">0.1f</span><span class="p">,</span><span class="s">&quot;initialAccumulatorValue&quot;</span><span class="p">,</span><span class="mf">0.01f</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also need to create an object to convert from Tribuo's feature representation to a TensorFlow <code>Tensor</code>, and an object that can convert to and from <code>Tensor</code> and <code>Regressor</code>. These are defined using the <code>ExampleTransformer</code> and <code>OutputTransformer</code> interfaces.</p>
<h3 id="Converting-Features-into-Tensors-with-FeatureConverter">Converting Features into Tensors with FeatureConverter<a class="anchor-link" href="#Converting-Features-into-Tensors-with-FeatureConverter">&#182;</a></h3><p>Tribuo provides two implementations of <code>FeatureConverter</code>, one for dense inputs (like those used by MLPs) called <code>DenseFeatureConverter</code> and one for image shaped inputs (like those used by CNNs) called <code>ImageConverter</code>. If you need more specialised transformations (e.g., text) then you should implement the <code>FeatureConverter</code> interface and tailor it to your task's needs.</p>
<p>The <code>FeatureConverter</code> needs the name of the input placeholder which the features will be fed into, so it can produce the appropriate values in the Map that is fed into the TensorFlow graph.</p>
<h3 id="Converting-Outputs-into-Tensors-(and-back-again)-with-OutputConverter">Converting Outputs into Tensors (and back again) with OutputConverter<a class="anchor-link" href="#Converting-Outputs-into-Tensors-(and-back-again)-with-OutputConverter">&#182;</a></h3><p>There are implementations of <code>OutputConverter</code> for <code>Label</code>, <code>MultiLabel</code> and <code>Regressor</code>, as those cover the main use cases for TensorFlow. You are free to implement these interfaces for more specialised use cases, though they should be thread-safe and idempotent. The <code>OutputConverter</code> contains the loss function and output function which is used to attach the appropriate training hooks to the graph. <code>LabelConverter</code> uses the <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> function to produce probabilistic outputs, and the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy">Categorical Cross Entropy</a> to provide the loss for back-propagation. <code>RegressorConverter</code> uses the identity function to produce the output (as it's already producing a real value), and the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError">Mean-Squared Error</a> as the loss function. <code>MultiLabelConverter</code> uses an independent sigmoid function for each label as the output, thresholded at 0.5, and <a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy">Binary Cross Entropy</a> as the loss function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineDenseConverter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DenseFeatureConverter</span><span class="p">(</span><span class="n">wineInputName</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineOutputConverter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RegressorConverter</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're finally ready to build our first <code>TensorFlowTrainer</code>. We need to specify a few more parameters in the constructor, namely the training batch size, the test batch size, and the number of training epochs. We'll set the batch sizes to 16 for all experiments, and we use 100 epochs for the regression task (because it's a small dataset), 20 epochs for the MNIST MLP, and 3 for the MNIST CNN (as the CNN converges much faster than the MLP).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TensorFlowTrainer</span><span class="o">&lt;</span><span class="n">Regressor</span><span class="o">&gt;</span><span class="p">(</span><span class="n">wineGraph</span><span class="p">,</span>
                <span class="n">wineOutputName</span><span class="p">,</span>
                <span class="n">wineInitName</span><span class="p">,</span>
                <span class="n">gradAlgorithm</span><span class="p">,</span>
                <span class="n">gradParams</span><span class="p">,</span>
                <span class="n">wineDenseConverter</span><span class="p">,</span>
                <span class="n">wineOutputConverter</span><span class="p">,</span>
                <span class="mi">16</span><span class="p">,</span>   <span class="c1">// training batch size</span>
                <span class="mi">100</span><span class="p">,</span>  <span class="c1">// number of training epochs</span>
                <span class="mi">16</span><span class="p">,</span>   <span class="c1">// test batch size of the trained model</span>
                <span class="o">-</span><span class="mi">1</span>    <span class="c1">// disable logging of the loss value</span>
                <span class="p">);</span>

<span class="c1">// Now we close the original graph to free the associated native resources.</span>
<span class="c1">// The TensorFlowTrainer keeps a copy of the GraphDef protobuf to rebuild it when necessary.</span>
<span class="n">wineGraph</span><span class="p">.</span><span class="na">close</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>TensorFlowTrainer</code> will accept a <code>Graph</code>, a <code>GraphDef</code> protobuf, or a path to a <code>GraphDef</code> protobuf on disk. The <code>Graph</code> should be closed after it's supplied to the trainer, to free the native resources associated with it. Tribuo manages a copy of the <code>Graph</code> inside the trainer so users don't need to worry about resource allocation. The trainer automatically adds the loss function, gradient update operations and the final output operation to the supplied graph.</p>
<p>We can use this trainer the way we'd use any other Tribuo trainer, we call <code>trainer.train()</code> and pass it in a dataset. In the case of TensorFlow it will throw an IllegalArgumentException if the number of features or outputs in the training dataset doesn't match what the trainer is expecting, as those parameters are coupled to the graph structure.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineStart</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">wineModel</span> <span class="o">=</span> <span class="n">wineTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">wineTrain</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">wineEnd</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Wine quality training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">wineStart</span><span class="p">,</span><span class="n">wineEnd</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wine quality training took (00:00:01:421)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we can evaluate it in the same way we evaluate other Tribuo regression models:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">wineEvaluation</span> <span class="o">=</span> <span class="n">regEval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">wineModel</span><span class="p">,</span><span class="n">wineTest</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">dimension</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Regressor</span><span class="p">(</span><span class="s">&quot;DIM-0&quot;</span><span class="p">,</span><span class="n">Double</span><span class="p">.</span><span class="na">NaN</span><span class="p">);</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">String</span><span class="p">.</span><span class="na">format</span><span class="p">(</span><span class="s">&quot;Wine quality evaluation:%n  RMSE %f%n  MAE %f%n  R^2 %f%n&quot;</span><span class="p">,</span>
            <span class="n">wineEvaluation</span><span class="p">.</span><span class="na">rmse</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span>
            <span class="n">wineEvaluation</span><span class="p">.</span><span class="na">mae</span><span class="p">(</span><span class="n">dimension</span><span class="p">),</span>
            <span class="n">wineEvaluation</span><span class="p">.</span><span class="na">r2</span><span class="p">(</span><span class="n">dimension</span><span class="p">)));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Wine quality evaluation:
  RMSE 0.650110
  MAE 0.507774
  R^2 0.350089

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see the MLP did ok there, and it's managed to fit the task almost as well as the tree ensemble we showed in the regression tutorial. With further tuning of the architecture and gradient parameters we could improve on this, but let's move on to classification.</p>
<h2 id="Building-a-classification-model-using-an-MLP">Building a classification model using an MLP<a class="anchor-link" href="#Building-a-classification-model-using-an-MLP">&#182;</a></h2><p>Building classification models using the TensorFlow interface is pretty similar to building regression models, thanks to Tribuo's common API for these tasks. The differences come in the choice of <code>OutputConverter</code>.</p>
<p>We're going to use Tribuo's <code>MLPExamples</code> and <code>CNNExamples</code> to build the networks for MNIST, as it's a bit shorter. These classes build simple predefined TensorFlow <code>Graph</code>s which are useful for demos, Tribuo's tests and getting started with deep learning. Currently there aren't many options in those classes, but we plan to expand them over time, and we welcome community contributions to do so. If you're interested in how the graphs are constructed you can check out the source for them on <a href="https://github.com/oracle/tribuo">GitHub</a>. For complex tasks we recommend that users build their own <code>Graph</code>s just as we did in the regression portion of the tutorial. TensorFlow-Java exposes a wide variety of <a href="https://tensorflow.org/jvm">operations</a> for building graphs, and as the high level API improves it will become easier to specify complex structures.</p>
<p>Tribuo's graph building functions return a <code>GraphDefTuple</code>, which is a nominal tuple for a <code>GraphDef</code> along with the strings representing the necessary operation names. As Tribuo targets Java 8 and upwards it's not a <code>java.lang.Record</code>, but it will be one day.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mnistInputName</span> <span class="o">=</span> <span class="s">&quot;MNIST_INPUT&quot;</span><span class="p">;</span>
<span class="kd">var</span> <span class="n">mnistMLPTuple</span> <span class="o">=</span> <span class="n">MLPExamples</span><span class="p">.</span><span class="na">buildMLPGraph</span><span class="p">(</span>
                        <span class="n">mnistInputName</span><span class="p">,</span> <span class="c1">// The input placeholder name</span>
                        <span class="n">mnistTrain</span><span class="p">.</span><span class="na">getFeatureMap</span><span class="p">().</span><span class="na">size</span><span class="p">(),</span> <span class="c1">// The number of input features</span>
                        <span class="k">new</span> <span class="kt">int</span><span class="o">[]</span><span class="p">{</span><span class="mi">300</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span><span class="mi">30</span><span class="p">},</span> <span class="c1">// The hidden layer sizes</span>
                        <span class="n">mnistTrain</span><span class="p">.</span><span class="na">getOutputs</span><span class="p">().</span><span class="na">size</span><span class="p">()</span> <span class="c1">// The number of output labels</span>
                        <span class="p">);</span>
<span class="kd">var</span> <span class="n">mnistDenseConverter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DenseFeatureConverter</span><span class="p">(</span><span class="n">mnistInputName</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">mnistOutputConverter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LabelConverter</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This built an MLP with 3 hidden layers. The first maps from the feature space to an internal dimension of size 300, then the second is also of size 200, and the third has an internal dimension of 30. Tribuo then adds an output layer mapping down from those 30 dimensions to the 10 output dimensions in MNIST, one per digit.</p>
<p>We'll use the same gradient optimiser as before, along with the same hyperparameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mnistMLPTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TensorFlowTrainer</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mnistMLPTuple</span><span class="p">.</span><span class="na">graphDef</span><span class="p">,</span>
                <span class="n">mnistMLPTuple</span><span class="p">.</span><span class="na">outputName</span><span class="p">,</span> <span class="c1">// the name of the logit operation</span>
                <span class="n">mnistMLPTuple</span><span class="p">.</span><span class="na">initName</span><span class="p">,</span>   <span class="c1">// the name of the initialisation operation</span>
                <span class="n">gradAlgorithm</span><span class="p">,</span>            <span class="c1">// the gradient descent algorithm</span>
                <span class="n">gradParams</span><span class="p">,</span>               <span class="c1">// the gradient descent hyperparameters</span>
                <span class="n">mnistDenseConverter</span><span class="p">,</span>      <span class="c1">// the input feature converter</span>
                <span class="n">mnistOutputConverter</span><span class="p">,</span>     <span class="c1">// the output label converter</span>
                <span class="mi">16</span><span class="p">,</span>  <span class="c1">// training batch size</span>
                <span class="mi">20</span><span class="p">,</span>  <span class="c1">// number of training epochs</span>
                <span class="mi">16</span><span class="p">,</span>  <span class="c1">// test batch size of the trained model</span>
                <span class="o">-</span><span class="mi">1</span>   <span class="c1">// disable logging of the loss value</span>
                <span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And we train the model as before:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mlpStart</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">mlpModel</span> <span class="o">=</span> <span class="n">mnistMLPTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">mnistTrain</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">mlpEnd</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;MNIST MLP training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">mlpStart</span><span class="p">,</span><span class="n">mlpEnd</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>MNIST MLP training took (00:00:50:286)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And evaluate it in the standard way:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mlpEvaluation</span> <span class="o">=</span> <span class="n">labelEval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">mlpModel</span><span class="p">,</span><span class="n">mnistTest</span><span class="p">);</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">mlpEvaluation</span><span class="p">.</span><span class="na">toString</span><span class="p">());</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">mlpEvaluation</span><span class="p">.</span><span class="na">getConfusionMatrix</span><span class="p">().</span><span class="na">toString</span><span class="p">());</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Class                           n          tp          fn          fp      recall        prec          f1
0                             980         952          28          42       0.971       0.958       0.965
1                           1,135       1,112          23          14       0.980       0.988       0.984
2                           1,032         956          76          72       0.926       0.930       0.928
3                           1,010         944          66          97       0.935       0.907       0.921
4                             982         916          66          50       0.933       0.948       0.940
5                             892         793          99          34       0.889       0.959       0.923
6                             958         924          34          39       0.965       0.960       0.962
7                           1,028         973          55          31       0.946       0.969       0.958
8                             974         910          64         126       0.934       0.878       0.905
9                           1,009         931          78          84       0.923       0.917       0.920
Total                      10,000       9,411         589         589
Accuracy                                                                    0.941
Micro Average                                                               0.941       0.941       0.941
Macro Average                                                               0.940       0.941       0.941
Balanced Error Rate                                                         0.060
               0       1       2       3       4       5       6       7       8       9
0            952       0       7       2       2       2       8       2       5       0
1              0   1,112       2       2       0       1       4       1       9       4
2              9       0     956      32       4       3       4       6      16       2
3              0       0      23     944       1       6       0       5      25       6
4              3       1       7       2     916       0      10       1       6      36
5              7       2      10      21       3     793      12       1      41       2
6              8       2       4       0       6       8     924       0       6       0
7              2       2      13       6       2       4       0     973       2      24
8              5       0       3      18      13       8       1       6     910      10
9              8       7       3      14      19       2       0       9      16     931

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>An MLP works pretty well on MNIST, but when working with images it's usually better to exploit the natural structure, and for that we use a Convolutional Neural Network.</p>
<h2 id="Training-a-Convolutional-Neural-Network">Training a Convolutional Neural Network<a class="anchor-link" href="#Training-a-Convolutional-Neural-Network">&#182;</a></h2><p>This is an even smaller transition than the switch between regression and classification. All we need to do is supply a <code>ImageConverter</code> which knows the size and pixel depth of the images, and build an appropriately shaped CNN.</p>
<p>We'll use <code>CNNExamples.buildLeNetGraph</code> to build a version of the venerable <a href="http://yann.lecun.com/exdb/lenet/">LeNet 5</a> CNN. We specify the image shape (this method assumes images are square), the pixel depth and the number of outputs. So for MNIST that's 28 pixels across, a pixel depth of 255, and 10 output classes one per digit. We'll also need the appropriate <code>ImageConverter</code> which needs the name of the input placeholder, the width and height of the image (so allowing rectangular images), and the number of colour channels. MNIST is grayscale, so there's only a single colour channel.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mnistCNNTuple</span> <span class="o">=</span> <span class="n">CNNExamples</span><span class="p">.</span><span class="na">buildLeNetGraph</span><span class="p">(</span><span class="n">mnistInputName</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="n">mnistTrain</span><span class="p">.</span><span class="na">getOutputs</span><span class="p">().</span><span class="na">size</span><span class="p">());</span>
<span class="kd">var</span> <span class="n">mnistImageConverter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ImageConverter</span><span class="p">(</span><span class="n">mnistInputName</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can build the trainer and train in the same way as before, but we will train for fewer epochs as the CNN converges faster:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">mnistCNNTrainer</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TensorFlowTrainer</span><span class="o">&lt;</span><span class="n">Label</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mnistCNNTuple</span><span class="p">.</span><span class="na">graphDef</span><span class="p">,</span>
                <span class="n">mnistCNNTuple</span><span class="p">.</span><span class="na">outputName</span><span class="p">,</span> <span class="c1">// the name of the logit operation</span>
                <span class="n">mnistCNNTuple</span><span class="p">.</span><span class="na">initName</span><span class="p">,</span>   <span class="c1">// the name of the initialisation operation</span>
                <span class="n">gradAlgorithm</span><span class="p">,</span>            <span class="c1">// the gradient descent algorithm</span>
                <span class="n">gradParams</span><span class="p">,</span>               <span class="c1">// the gradient descent hyperparameters</span>
                <span class="n">mnistImageConverter</span><span class="p">,</span>      <span class="c1">// the input feature converter</span>
                <span class="n">mnistOutputConverter</span><span class="p">,</span>     <span class="c1">// the output label converter</span>
                <span class="mi">16</span><span class="p">,</span> <span class="c1">// training batch size</span>
                <span class="mi">3</span><span class="p">,</span>  <span class="c1">// number of training epochs</span>
                <span class="mi">16</span><span class="p">,</span> <span class="c1">// test batch size of the trained model</span>
                <span class="o">-</span><span class="mi">1</span>  <span class="c1">// disable logging of the loss value</span>
                <span class="p">);</span>
                
<span class="c1">// Training the model</span>
<span class="kd">var</span> <span class="n">cnnStart</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">cnnModel</span> <span class="o">=</span> <span class="n">mnistCNNTrainer</span><span class="p">.</span><span class="na">train</span><span class="p">(</span><span class="n">mnistTrain</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">cnnEnd</span> <span class="o">=</span> <span class="n">System</span><span class="p">.</span><span class="na">currentTimeMillis</span><span class="p">();</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;MNIST CNN training took &quot;</span> <span class="o">+</span> <span class="n">Util</span><span class="p">.</span><span class="na">formatDuration</span><span class="p">(</span><span class="n">cnnStart</span><span class="p">,</span><span class="n">cnnEnd</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>MNIST CNN training took (00:02:40:480)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And evaluate it the standard way:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">cnnPredictions</span> <span class="o">=</span> <span class="n">cnnModel</span><span class="p">.</span><span class="na">predict</span><span class="p">(</span><span class="n">mnistTest</span><span class="p">);</span>
<span class="kd">var</span> <span class="n">cnnEvaluation</span> <span class="o">=</span> <span class="n">labelEval</span><span class="p">.</span><span class="na">evaluate</span><span class="p">(</span><span class="n">cnnModel</span><span class="p">,</span><span class="n">cnnPredictions</span><span class="p">,</span><span class="n">mnistTest</span><span class="p">.</span><span class="na">getProvenance</span><span class="p">());</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">cnnEvaluation</span><span class="p">.</span><span class="na">toString</span><span class="p">());</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="n">cnnEvaluation</span><span class="p">.</span><span class="na">getConfusionMatrix</span><span class="p">().</span><span class="na">toString</span><span class="p">());</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Class                           n          tp          fn          fp      recall        prec          f1
0                             980         968          12          25       0.988       0.975       0.981
1                           1,135       1,123          12           9       0.989       0.992       0.991
2                           1,032       1,020          12          55       0.988       0.949       0.968
3                           1,010         980          30          24       0.970       0.976       0.973
4                             982         963          19          27       0.981       0.973       0.977
5                             892         873          19          46       0.979       0.950       0.964
6                             958         922          36           8       0.962       0.991       0.977
7                           1,028         960          68          13       0.934       0.987       0.960
8                             974         937          37          22       0.962       0.977       0.969
9                           1,009         978          31          47       0.969       0.954       0.962
Total                      10,000       9,724         276         276
Accuracy                                                                    0.972
Micro Average                                                               0.972       0.972       0.972
Macro Average                                                               0.972       0.972       0.972
Balanced Error Rate                                                         0.028
               0       1       2       3       4       5       6       7       8       9
0            968       0       3       0       0       1       3       1       3       1
1              0   1,123       3       0       2       1       2       0       4       0
2              1       1   1,020       3       3       0       1       1       1       1
3              1       0       6     980       0      15       0       3       4       1
4              0       0       3       1     963       0       1       0       1      13
5              1       0       0       9       0     873       1       1       2       5
6             13       3       2       1       2      11     922       0       3       1
7              0       1      28       8       7       1       0     960       2      21
8              8       0       9       1       2      11       0       2     937       4
9              1       4       1       1      11       6       0       5       2     978

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we might expect, exploiting the structured nature of images lets us get better performance, with 97% accuracy after only 3 epochs. There is a wide variety of different CNN architectures, each suited for different kinds of tasks. Some are even applied to sequential data like text.</p>
<h2 id="Exporting-and-Importing-TensorFlow-models">Exporting and Importing TensorFlow models<a class="anchor-link" href="#Exporting-and-Importing-TensorFlow-models">&#182;</a></h2><p>TensorFlow's canonical model storage format is the <a href="https://www.tensorflow.org/guide/saved_model"><code>SavedModelBundle</code></a>. You can export TensorFlow models trained in Tribuo in this format by calling <code>model.exportModel(String path)</code> which writes a directory at that path which contains the model as a <code>SavedModel</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">outputPath</span> <span class="o">=</span> <span class="s">&quot;./tf-cnn-mnist-model&quot;</span><span class="p">;</span>
<span class="n">cnnModel</span><span class="p">.</span><span class="na">exportModel</span><span class="p">(</span><span class="n">outputPath</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tribuo can also load in <code>SavedModel</code>s and serve them as an <code>ExternalModel</code>. See the external models tutorial for more details on how Tribuo works with models built in other packages. The short version is that you need to specify the mapping from Tribuo's feature names into the id numbers the model expects, and from the output indices to Tribuo's output dimensions. We'll show how to load in the CNN that we just exported, and validate that it gives the same predictions as the original.</p>
<p>First we'll setup the feature and output mappings. This is easy in our case as we already have the relevant information, but in most cases this requires understanding how the features were prepared when the original model was trained. We discuss this in more detail in the external models tutorial.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">outputMapping</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">Label</span><span class="p">,</span><span class="n">Integer</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">p</span> <span class="p">:</span> <span class="n">cnnModel</span><span class="p">.</span><span class="na">getOutputIDInfo</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">outputMapping</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="na">getB</span><span class="p">(),</span><span class="n">p</span><span class="p">.</span><span class="na">getA</span><span class="p">());</span>
<span class="p">}</span>
<span class="kd">var</span> <span class="n">featureIDMap</span> <span class="o">=</span> <span class="n">cnnModel</span><span class="p">.</span><span class="na">getFeatureIDMap</span><span class="p">();</span>
<span class="kd">var</span> <span class="n">featureMapping</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="n">Integer</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="n">info</span> <span class="p">:</span> <span class="n">featureIDMap</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">featureMapping</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">info</span><span class="p">.</span><span class="na">getName</span><span class="p">(),</span><span class="n">featureIDMap</span><span class="p">.</span><span class="na">getID</span><span class="p">(</span><span class="n">info</span><span class="p">.</span><span class="na">getName</span><span class="p">()));</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we build the <code>TensorFlowSavedModelExternalModel</code> using it's factory, supplying the feature mapping, output mapping, the softmax output operation name, the image transformer, the label transformer and finally the path to the <code>SavedModel</code> on disk.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">externalModel</span> <span class="o">=</span> <span class="n">TensorFlowSavedModelExternalModel</span><span class="p">.</span><span class="na">createTensorflowModel</span><span class="p">(</span>
                        <span class="n">labelFactory</span><span class="p">,</span>             <span class="c1">// the output factory</span>
                        <span class="n">featureMapping</span><span class="p">,</span>           <span class="c1">// the feature mapping</span>
                        <span class="n">outputMapping</span><span class="p">,</span>            <span class="c1">// the output mapping</span>
                        <span class="n">cnnModel</span><span class="p">.</span><span class="na">getOutputName</span><span class="p">(),</span> <span class="c1">// the name of the *softmax* output</span>
                        <span class="n">mnistImageConverter</span><span class="p">,</span>      <span class="c1">// the input feature converter</span>
                        <span class="n">mnistOutputConverter</span><span class="p">,</span>     <span class="c1">// The label converter</span>
                        <span class="n">outputPath</span><span class="p">.</span><span class="na">toString</span><span class="p">()</span>     <span class="c1">// path to the saved model</span>
                        <span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This model behaves like any other, so we pass it some test data and generate it's predictions.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">externalPredictions</span> <span class="o">=</span> <span class="n">externalModel</span><span class="p">.</span><span class="na">predict</span><span class="p">(</span><span class="n">mnistTest</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's compare the output predictions. It's a little convoluted, but we're going to compare each predicted probability distribution to make sure they are the same.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-java"><pre><span></span><span class="kd">var</span> <span class="n">isEqual</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">cnnPredictions</span><span class="p">.</span><span class="na">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="n">tribuo</span> <span class="o">=</span> <span class="n">cnnPredictions</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
    <span class="kd">var</span> <span class="n">external</span> <span class="o">=</span> <span class="n">externalPredictions</span><span class="p">.</span><span class="na">get</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
    <span class="n">isEqual</span> <span class="o">&amp;=</span> <span class="n">tribuo</span><span class="p">.</span><span class="na">getOutput</span><span class="p">().</span><span class="na">fullEquals</span><span class="p">(</span><span class="n">external</span><span class="p">.</span><span class="na">getOutput</span><span class="p">());</span>
    <span class="n">isEqual</span> <span class="o">&amp;=</span> <span class="n">tribuo</span><span class="p">.</span><span class="na">distributionEquals</span><span class="p">(</span><span class="n">external</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">println</span><span class="p">(</span><span class="s">&quot;Predictions are &quot;</span> <span class="o">+</span> <span class="p">(</span><span class="n">isEqual</span> <span class="o">?</span> <span class="s">&quot;equal&quot;</span> <span class="p">:</span> <span class="s">&quot;not equal&quot;</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Predictions are equal
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As we can see, the models produce identical predictions, which means that we've successfully exported all our model weights and managed to load them back in as an external model.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><p>We saw how to build MLPs and CNNs in Tribuo &amp; TensorFlow for both regression and classification, along with how to export Tribuo-trained models into TensorFlow's format, and import TensorFlow SavedModels into Tribuo.</p>
<p>By default Tribuo pulls in the CPU version of TensorFlow Java, but if you supply the GPU jar at runtime it will automatically run everything on a compatible Nvidia GPU. We'll look at exposing explicit GPU support from Tribuo as the relevant support matures in TensorFlow Java.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

